{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6864_hw1_part_3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-yFF2rKuuh6U"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexmijo/6.806-Homeworks/blob/main/6864_hw1_part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5R8vijdeKgl"
      },
      "source": [
        "import csv\n",
        "import itertools as it\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "import lab_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaoYiysseNIH"
      },
      "source": [
        "## Hidden Markov Models\n",
        "\n",
        "In the remaining part of the lab (containing part 3) you'll use the Baum--Welch algorithm to learn _categorical_ representations of words in your vocabulary. Answers to questions in this lab should go in the same report as the initial release.\n",
        "\n",
        "As before, we'll start by loading up a dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUn-q_pIeuAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb5faf4-6ce0-4d36-ec87-58801903e631"
      },
      "source": [
        "data = []\n",
        "n_positive = 0\n",
        "n_disp = 0\n",
        "with open(\"reviews.csv\") as reader:\n",
        "  csvreader = csv.reader(reader)\n",
        "  next(csvreader)\n",
        "  for id, review, label in csvreader:\n",
        "    label = int(label)\n",
        "\n",
        "    # hacky class balancing\n",
        "    if label == 1:\n",
        "      if n_positive == 2000:\n",
        "        continue\n",
        "      n_positive += 1\n",
        "    if len(data) == 4000:\n",
        "      break\n",
        "\n",
        "    data.append((review, label))\n",
        "    \n",
        "    if n_disp > 5:\n",
        "      continue\n",
        "    n_disp += 1\n",
        "    print(\"review:\", review)\n",
        "    print(\"rating:\", label, \"(good)\" if label == 1 else \"(bad)\")\n",
        "    print()\n",
        "\n",
        "print(f\"Read {len(data)} total reviews.\")\n",
        "np.random.shuffle(data)\n",
        "reviews, labels = zip(*data)\n",
        "train_reviews = reviews[:3000]\n",
        "train_labels = labels[:3000]\n",
        "val_reviews = reviews[3000:3500]\n",
        "val_labels = labels[3000:3500]\n",
        "test_reviews = reviews[3500:]\n",
        "test_labels = labels[3500:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review: I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
            "rating: 1 (good)\n",
            "\n",
            "review: Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
            "rating: 0 (bad)\n",
            "\n",
            "review: This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
            "rating: 1 (good)\n",
            "\n",
            "review: If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.\n",
            "rating: 0 (bad)\n",
            "\n",
            "review: Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
            "rating: 1 (good)\n",
            "\n",
            "review: I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.\n",
            "rating: 1 (good)\n",
            "\n",
            "Read 4000 total reviews.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2qlqRHoe3y-"
      },
      "source": [
        "Next, implement the forward--backward algorithm for HMMs like we saw in class.\n",
        "\n",
        "**IMPORTANT NOTE**: if you directly multiply probabilities as shown on the class slides, you'll get underflow errors. You'll probably want to work in the log domain (remember that `log(ab) = log(a) + log(b)`, `log(exp(a) + exp(b)) = logaddexp(a, b)`). In general, we recommend either `np.logaddexp` or `scipy.special.logsumexp` as safe ways to compute the necessary quantities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wVf4QVIfBdc"
      },
      "source": [
        "from scipy import special\n",
        "\n",
        "# hmm model\n",
        "class HMM(object):\n",
        "    def __init__(self, num_states, num_words):\n",
        "        self.num_states = num_states\n",
        "        self.num_words = num_words\n",
        "\n",
        "        self.states = range(num_states)\n",
        "        self.symbols = range(num_words)\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the matrix A with random transition probabilities p(j|i)\n",
        "        A should be a matrix of size `num_states x num_states` with rows that\n",
        "        sum to 1.\n",
        "        \"\"\"\n",
        "        self.A = np.random.rand(num_states, num_states)\n",
        "        self.A = self.A / self.A.sum(axis=1, keepdims=True)\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the matrix B with random emission probabilities p(o|i). B \n",
        "        should be a matrix of size `num_states x num_words` with rows that sum \n",
        "        to 1.\n",
        "        \"\"\"\n",
        "        self.B = np.random.rand(num_states, num_words)\n",
        "        self.B = self.B / self.B.sum(axis=1, keepdims=True)\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the vector pi with a random starting distribution. pi should\n",
        "        be a vector of size `num_states` with entries that sum to 1.\n",
        "        \"\"\"\n",
        "        self.pi = np.random.rand(num_states)\n",
        "        self.pi = self.pi / self.pi.sum()\n",
        "\n",
        "    def generate(self, n):\n",
        "        \"\"\"randomly sample the HMM to generate a sequence.\n",
        "        \"\"\"\n",
        "        # we'll give you this one\n",
        "\n",
        "        sequence = []\n",
        "        # initialize the first state\n",
        "        state = np.random.choice(self.states, p=self.pi)\n",
        "        for i in range(n):\n",
        "            # get the emission probs for this state\n",
        "            b = self.B[state, :]\n",
        "            # emit a word\n",
        "            word = np.random.choice(self.symbols, p=b)\n",
        "            sequence.append(word)\n",
        "            # get the transition probs for this state\n",
        "            a = self.A[state, :]\n",
        "            # update the state\n",
        "            state = np.random.choice(self.states, p=a)\n",
        "        return sequence\n",
        "\n",
        "    def forward(self, obs):\n",
        "        \"\"\"\n",
        "        Runs the forward algorithm. This function should return a \n",
        "        `len(obs) x  num_states` matrix where the (t, i)th entry contains \n",
        "        log p(obs[:t], hidden_state_t = i)\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = np.zeros((len(obs), self.num_states))\n",
        "        logA = np.log(self.A)\n",
        "        logB = np.log(self.B)\n",
        "        logPi = np.log(self.pi)\n",
        "\n",
        "        alpha[0] = logPi + logB[:, obs[0]]\n",
        "\n",
        "        for t in range(len(obs) - 1):\n",
        "            alpha[t + 1] = scipy.special.logsumexp(alpha[t][:, None] + logA,\\\n",
        "                                                   axis=0) + logB[:, obs[t + 1]]\n",
        "\n",
        "        return alpha\n",
        "\n",
        "    def backward(self, obs):\n",
        "        \"\"\"\n",
        "        Run the backward algorithm. This function should return a\n",
        "        `len(obs) x num_states` matrix where the (t, i)th entry contains\n",
        "        log p(obs[t+1:] | hidden_state_t = i)\n",
        "        \"\"\"\n",
        "\n",
        "        beta = np.zeros((len(obs), self.num_states))\n",
        "        logA = np.log(self.A)\n",
        "        logB = np.log(self.B)\n",
        "\n",
        "        for t in range(len(obs) - 2, -1, -1):\n",
        "            beta[t] = scipy.special.logsumexp(logA + logB[:, obs[t + 1]] +\\\n",
        "                                              beta[t + 1], axis=1)\n",
        "\n",
        "        return beta\n",
        "        \n",
        "    def forward_backward(self, obs):\n",
        "        \"\"\"\n",
        "        Compute forward-backward scores\n",
        "\n",
        "        logprob is the total log-probability of the sequence obs (marginalizing\n",
        "        over hidden states).\n",
        "\n",
        "        gamma is a matrix of size `len(obs) x num_states1. It contains the\n",
        "        marginal probability of being in state i at time t\n",
        "\n",
        "        xi is a tensor of size `len(obs) - 1 x num_states x num_states`. It contains\n",
        "        the marginal probability of transitioning from i to j at t.\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.forward(obs)\n",
        "        beta = self.backward(obs)\n",
        "        logA = np.log(self.A)\n",
        "        logB = np.log(self.B)\n",
        "\n",
        "        logprob = scipy.special.logsumexp(alpha[-1])\n",
        "        xi = np.zeros((len(obs) - 1, self.num_states, self.num_states))\n",
        "        for t in range(len(obs) - 1):\n",
        "            xi[t] = alpha[t][:, None] + logA + logB[:, obs[t + 1]] +\\\n",
        "             beta[t + 1] - logprob\n",
        "        gamma = alpha + beta - logprob\n",
        "\n",
        "        return logprob, np.exp(xi), np.exp(gamma)\n",
        "\n",
        "        \"\"\"\n",
        "        SANITY CHECK\n",
        "\n",
        "        The most straightforward way of implementing the forward, backward, and \n",
        "        forward_backward methods would be to iterate through all the values and \n",
        "        use the formulas in the slides to calculate the corresponding values.\n",
        "\n",
        "        However, this may not be fast enough. If your model is taking too long\n",
        "        to train, consider how you may speed up your code by reducing the number\n",
        "        of for loops involved. How can you reformulate your code using matrix\n",
        "        operations?\n",
        "\n",
        "        Hint: we were able to implement each of the forward, backward, and\n",
        "        forward_backward operations using only one for loop.\n",
        "        \"\"\"\n",
        "\n",
        "    def learn_unsupervised(self, corpus, num_iters, print_every=10):\n",
        "        \"\"\"Run the Baum Welch EM algorithm\n",
        "        \n",
        "        corpus: the data to learn from\n",
        "        num_iters: the number of iterations to run the algorithm\n",
        "        print_every: how often to print the log-likelihood while the model is\n",
        "        updating its parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        for i_iter in range(num_iters):\n",
        "            \"\"\"\n",
        "            expected_si: a vector of size (num_states,) where the i-th entry is\n",
        "            the expected number of times a sentence is transitioning from state \n",
        "            i to some other state.\n",
        "\n",
        "            expected_sij: an array of size (num_states, num_states) where the\n",
        "            (i,j)-th entry represents the expected number of state transitions\n",
        "            between state i and state j.\n",
        "\n",
        "            expected_sjwk: an array of size (num_states, num_words) where the \n",
        "            (j,k)-th entry represents the expected number of times the word w_k \n",
        "            appears when at state j.\n",
        "\n",
        "            expected_sj: a vector of size (num_states,) where the j-th entry is\n",
        "            the expected number of times a sentence is in state j (differing \n",
        "            from expected_si by also including end states).\n",
        "\n",
        "            expected_q1: a vector of size (num_states,) where the i-th entry is \n",
        "            the expected number of times state i is the first state.\n",
        "\n",
        "            total_logprob: The log of the probability of the corpus being\n",
        "            generated with the current parameters of the HMM.\n",
        "            \"\"\"\n",
        "            expected_si = np.zeros((self.num_states,))\n",
        "            expected_sij = np.zeros((self.num_states, self.num_states))\n",
        "            expected_sjwk = np.zeros((self.num_states, self.num_words))\n",
        "            expected_sj = np.zeros((self.num_states,))\n",
        "            expected_q1 = np.zeros((self.num_states))\n",
        "            total_logprob = 0\n",
        "            \n",
        "            for review in corpus:\n",
        "                logprob, xi, gamma = self.forward_backward(review)\n",
        "                expected_si += np.sum(gamma[0:-1], axis=0)\n",
        "                expected_sij += np.sum(xi, axis=0)\n",
        "                for t in range(len(review)):\n",
        "                    k = review[t]\n",
        "                    expected_sjwk[:,k] += gamma[t]\n",
        "                expected_sj += np.sum(gamma, axis=0)\n",
        "                expected_q1 += gamma[0]\n",
        "                total_logprob += logprob\n",
        "            expected_q1 = expected_q1 / np.sum(expected_q1)\n",
        "            if i_iter % print_every == 0:\n",
        "              print(\"log-likelihood\", total_logprob)\n",
        "\n",
        "            \"\"\"\n",
        "            The following variables should be the new values of self.A, self.B,\n",
        "            and self.pi after the values are updated.\n",
        "            \"\"\"\n",
        "            A_new = expected_sij / expected_si[:, None]\n",
        "            B_new = expected_sjwk / expected_sj[:, None]\n",
        "            pi_new = expected_q1\n",
        "\n",
        "            self.A = A_new\n",
        "            self.B = B_new\n",
        "            self.pi = pi_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yFF2rKuuh6U"
      },
      "source": [
        "## Test Cases\n",
        "\n",
        "The following are test cases that are meant to help you debug your code. The code involves six test suites - an initialization test, a forward test, a backward test, a forward_backward test, a baum_welch_update test, and a final end_to_end test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3gRZ_r_vLav"
      },
      "source": [
        "def init_test():\n",
        "\n",
        "    num_states = np.random.randint(100)\n",
        "    num_words = np.random.randint(100)\n",
        "    model = HMM(num_states, num_words)\n",
        "\n",
        "    assert model.A.shape == (num_states, num_states)\n",
        "    assert model.B.shape == (num_states, num_words)\n",
        "    assert model.pi.shape == (num_states, )\n",
        "\n",
        "    assert np.linalg.norm(np.sum(model.A, axis=1) - np.ones(num_states)) < 1e-10\n",
        "    assert np.linalg.norm(np.sum(model.B, axis=1) - np.ones(num_states)) < 1e-10\n",
        "    assert np.linalg.norm(np.sum(model.pi) - 1) < 1e-10\n",
        "\n",
        "def forward_test():\n",
        "    model = HMM(2, 10)\n",
        "    model.A = np.array([[0.79034887, 0.20965113],\n",
        "                        [0.66824331, 0.33175669]])\n",
        "    model.B = np.array([[0.08511814, 0.06627238, 0.08487461, 0.15607959, 0.00124582, 0.12984083, 0.11164849, 0.11591902, 0.15232716, 0.09667395],\n",
        "                        [0.18425462, 0.14326559, 0.14026994, 0.0215989,  0.17687124, 0.04681278, 0.05857451, 0.17451212, 0.00473382, 0.04910648]])\n",
        "    model.pi = np.array([0.77480039, 0.22519961])\n",
        "    obs = [1, 8, 0, 0, 3, 4, 5, 2, 6, 3, 7, 9]\n",
        "    alpha = model.forward(obs)\n",
        "\n",
        "    print(\"The result of the forward function should be\", np.array([[-2.96913, -3.43382],\n",
        "                                                                    [ -4.66005, -9.19418],\n",
        "                                                                    [ -7.35001, -7.89695],\n",
        "                                                                    [ -9.65069, -9.95363],\n",
        "                                                                    [-11.25815, -14.27392],\n",
        "                                                                    [-18.14079, -14.4781 ],\n",
        "                                                                    [-16.89275, -18.62696],\n",
        "                                                                    [-19.45549, -20.17289],\n",
        "                                                                    [-21.53772, -23.283  ],\n",
        "                                                                    [-23.4927, -26.69119],\n",
        "                                                                    [-25.84891, -26.73817],\n",
        "                                                                    [-28.12237, -29.92402]]))\n",
        "    print(\"Your value of alpha is:\", np.round(alpha, 5))\n",
        "\n",
        "def backward_test():\n",
        "    model = HMM(2, 10)\n",
        "    model.A = np.array([[0.79034887, 0.20965113],\n",
        "                        [0.66824331, 0.33175669]])\n",
        "    model.B = np.array([[0.08511814, 0.06627238, 0.08487461, 0.15607959, 0.00124582, 0.12984083, 0.11164849, 0.11591902, 0.15232716, 0.09667395],\n",
        "                        [0.18425462, 0.14326559, 0.14026994, 0.0215989,  0.17687124, 0.04681278, 0.05857451, 0.17451212, 0.00473382, 0.04910648]])\n",
        "    model.pi = np.array([0.77480039, 0.22519961])\n",
        "    obs = [1, 8, 0, 0, 3, 4, 5, 2, 6, 3, 7, 9]\n",
        "    beta = model.backward(obs)\n",
        "\n",
        "    print(\"The result of the backward function should be\", np.array([[-25.42937, -25.58918], \n",
        "                                                                     [-23.32164, -23.19959],\n",
        "                                                                     [-21.11007, -21.02033],\n",
        "                                                                     [-18.82215, -18.94381],\n",
        "                                                                     [-16.78523, -16.33951],\n",
        "                                                                     [-13.42847, -13.51924],\n",
        "                                                                     [-11.24815, -11.19161],\n",
        "                                                                     [ -8.88679,  -8.96441],\n",
        "                                                                     [ -6.57374,  -6.70985],\n",
        "                                                                     [ -4.51873,  -4.47419],\n",
        "                                                                     [ -2.44529,  -2.51463],\n",
        "                                                                     [  0, 0]]))\n",
        "\n",
        "    print(\"Your value of beta is:\", np.round(beta, 5))\n",
        "\n",
        "\n",
        "def forward_backward_test():\n",
        "    model = HMM(2, 10)\n",
        "    model.A = np.array([[0.79034887, 0.20965113],\n",
        "                        [0.66824331, 0.33175669]])\n",
        "    model.B = np.array([[0.08511814, 0.06627238, 0.08487461, 0.15607959, 0.00124582, 0.12984083, 0.11164849, 0.11591902, 0.15232716, 0.09667395],\n",
        "                        [0.18425462, 0.14326559, 0.14026994, 0.0215989,  0.17687124, 0.04681278, 0.05857451, 0.17451212, 0.00473382, 0.04910648]])\n",
        "    model.pi = np.array([0.77480039, 0.22519961])\n",
        "    obs = [1, 8, 0, 0, 3, 4, 5, 2, 6, 3, 7, 9]\n",
        "    logprob, xi, gamma = model.forward_backward(obs)\n",
        "\n",
        "    print(\"The value of logprob should be:\", -27.9693)\n",
        "    print(\"Your value of logprob is:\", np.round(logprob, 5))\n",
        "\n",
        "    print(\"The value of xi should be:\", np.array([[[0.64523, 0.00601],\n",
        "                                                  [0.34278, 0.00598]],\n",
        "\n",
        "                                                 [[0.60684, 0.38117],\n",
        "                                                  [0.00551, 0.00648]],\n",
        "\n",
        "                                                 [[0.40595, 0.2064 ],\n",
        "                                                  [0.19863, 0.18902]],\n",
        "\n",
        "                                                 [[0.5718,  0.03278],\n",
        "                                                  [0.35711, 0.03831]],\n",
        "\n",
        "                                                 [[0.02625, 0.90266],\n",
        "                                                  [0.00109, 0.07   ]],\n",
        "\n",
        "                                                 [[0.02482, 0.00251],\n",
        "                                                  [0.81777, 0.15489]],\n",
        "\n",
        "                                                 [[0.59943, 0.24316],\n",
        "                                                  [0.08947, 0.06793]],\n",
        "\n",
        "                                                 [[0.6143,  0.07461],\n",
        "                                                  [0.25347, 0.05762]],\n",
        "\n",
        "                                                 [[0.8357,  0.03207],\n",
        "                                                  [0.12337, 0.00886]],\n",
        "\n",
        "                                                 [[0.69872, 0.26034],\n",
        "                                                  [0.02412, 0.01682]],\n",
        "\n",
        "                                                 [[0.63701, 0.08583],\n",
        "                                                  [0.22134, 0.05582]]]))\n",
        "    print(\"Your value of xi is:\", np.round(xi, 5))\n",
        "\n",
        "    print(\"The value of gamma should be:\", np.array([[0.65124, 0.34876],\n",
        "                                                    [0.98802, 0.01198],\n",
        "                                                    [0.61235, 0.38765],\n",
        "                                                    [0.60458, 0.39542],\n",
        "                                                    [0.92891, 0.07109],\n",
        "                                                    [0.02733, 0.97267],\n",
        "                                                    [0.8426,  0.1574 ],\n",
        "                                                    [0.68891, 0.31109],\n",
        "                                                    [0.86777, 0.13223],\n",
        "                                                    [0.95906, 0.04094],\n",
        "                                                    [0.72284, 0.27716],\n",
        "                                                    [0.85835, 0.14165]]))\n",
        "\n",
        "    print(\"Your value of gamma is:\", np.round(gamma, 5))\n",
        "\n",
        "def baum_welch_update_test():\n",
        "    model = HMM(4, 10)\n",
        "    \n",
        "    model.A = np.array([[0.05263151, 0.62161178, 0.06683182, 0.25892489],\n",
        "                        [0.26993274, 0.13114741, 0.32305468, 0.27586517],\n",
        "                        [0.2951958,  0.14576492, 0.22474111, 0.33429817],\n",
        "                        [0.29586018, 0.26065884, 0.1977772,  0.24570378]])\n",
        "    \n",
        "    model.B = np.array([[0.01800425, 0.09767131, 0.17824799, 0.12586453, 0.19514548, 0.05433139, 0.01995667, 0.12985343, 0.01884263, 0.16208232],\n",
        "                        [0.04512782, 0.09469685, 0.1426164,  0.13851362, 0.08717793, 0.17152532, 0.08746939, 0.04900339, 0.05315859, 0.13071069],\n",
        "                        [0.11055806, 0.10592473, 0.0051817,  0.07721441, 0.21761783, 0.20323146, 0.18881598, 0.00584989, 0.00682669, 0.07877924],\n",
        "                        [0.08711377, 0.16703645, 0.0706214,  0.05297571, 0.10486868, 0.16794587, 0.13562053, 0.15729142, 0.03345308, 0.02307309]])\n",
        "    \n",
        "    model.pi = np.array([0.21186864, 0.27156561, 0.37188523, 0.14468051])\n",
        "    \n",
        "    corpus = np.array([[7,3,2,5,0,3,2,9,4,2], [7,3,2,4,2,8,7,5,0,8], [7,3,2,3,1,7,3,8,6,7], [7,3,2,6,4,4,3,4,0,0]])\n",
        "\n",
        "    model.learn_unsupervised(corpus, 200)\n",
        "\n",
        "    print(\"hmm.A should be\", np.array([[0, 1, 0, 0], \n",
        "                                     [0.14122, 0, 0.27099, 0.58779], \n",
        "                                     [0.20671, 0, 0, 0.79329], \n",
        "                                     [0, 0.90909, 0.09091, 0]]))\n",
        "    print(\"Your implementation has hmm.A to be\", np.round(model.A, 5))\n",
        "\n",
        "    print(\"hmm.B should be\", np.array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "                                              [0.0625, 0, 0, 0.5, 0, 0.125, 0.125, 0, 0.125, 0.0625],\n",
        "                                              [0, 0.20671, 0, 0, 0.79329, 0, 0, 0, 0, 0],\n",
        "                                              [0.24667, 0, 0.57555, 0, 0.09556, 0, 0, 0, 0.08222, 0]]))\n",
        "    print(\"Your implementation has hmm.B to be\", np.round(model.B, 5))\n",
        "\n",
        "    print(\"hmm.pi should be\", np.array([1, 0, 0, 0]))\n",
        "\n",
        "    print(\"Your implementation has hmm.pi to be\", np.round(model.pi, 5))\n",
        "\n",
        "def end_to_end_test():\n",
        "    # Test Case 1\n",
        "\n",
        "    corpus = np.array([[0,3,0,3,0,3,0,3,0,3,0,3], [0,2,0,2,0,2,0,2,0,2,0,2,0], [1,2,1,2,1,2,1,2,1,2,1,2],[1,3,1,3,1,3,1,3,1,3]])\n",
        "    hmm = HMM(num_states=2,num_words=4)\n",
        "    hmm.learn_unsupervised(corpus, 10)\n",
        "    print(\"After this test case, hmm.A should either be approximately,\",  np.array([[0, 1], [1, 0]]))\n",
        "    print(\"This is your current value of hmm.A: \", np.round(hmm.A, 5))\n",
        "\n",
        "    print(\"After this test case, hmm.B should either be approximately,\", np.array([[0, 0, 0.5, 0.5], [0.5, 0.5, 0, 0]]), \" or it should be \", np.array([[0.5, 0.5, 0, 0], [0, 0, 0.5, 0.5]]))\n",
        "    print(\"This is your current value of hmm.B: \", np.round(hmm.B, 5))\n",
        "\n",
        "    # Test Case 2\n",
        "\n",
        "    corpus = np.array([[0,0,0,0,0,0,0,0,0,0], [1,1,1,1,1,1,1,1,1,1], [2,2,2,2,2,2,2,2,2,2]])\n",
        "    hmm = HMM(num_states=3, num_words=3)\n",
        "    hmm.learn_unsupervised(corpus, 100)\n",
        "    print(\"After this test case, hmm.A should be the identity matrix\", np.eye(3))\n",
        "    print(\"This is your current value of hmm.A: \", np.round(hmm.A, 5))\n",
        "\n",
        "    print(\"After this test case, hmm.B should be some 3 by 3 permutation matrix\")\n",
        "    print(\"This is your current value of hmm.B: \", np.round(hmm.B, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmewPFV2MPlS"
      },
      "source": [
        "## Test\n",
        "\n",
        "To actually run the test cases, run the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFtzZ9W9MVKu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3802
        },
        "outputId": "00c2697b-732a-4963-ffd0-e57c36b4d9b0"
      },
      "source": [
        "init_test()\n",
        "forward_test()\n",
        "backward_test()\n",
        "forward_backward_test()\n",
        "baum_welch_update_test()\n",
        "end_to_end_test()\n",
        "\n",
        "\"\"\"\n",
        "Note: The end_to_end_test is not as robustg due to it using random starts. Try\n",
        "running the test case a few times to see if you get a good result at least a few\n",
        "times before deciding that your code is buggy.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result of the forward function should be [[ -2.96913  -3.43382]\n",
            " [ -4.66005  -9.19418]\n",
            " [ -7.35001  -7.89695]\n",
            " [ -9.65069  -9.95363]\n",
            " [-11.25815 -14.27392]\n",
            " [-18.14079 -14.4781 ]\n",
            " [-16.89275 -18.62696]\n",
            " [-19.45549 -20.17289]\n",
            " [-21.53772 -23.283  ]\n",
            " [-23.4927  -26.69119]\n",
            " [-25.84891 -26.73817]\n",
            " [-28.12237 -29.92402]]\n",
            "Your value of alpha is: [[ -2.96913  -3.43382]\n",
            " [ -4.66005  -9.19418]\n",
            " [ -7.35001  -7.89695]\n",
            " [ -9.65069  -9.95363]\n",
            " [-11.25815 -14.27392]\n",
            " [-18.14079 -14.4781 ]\n",
            " [-16.89275 -18.62697]\n",
            " [-19.45549 -20.17289]\n",
            " [-21.53772 -23.283  ]\n",
            " [-23.4927  -26.69119]\n",
            " [-25.84891 -26.73817]\n",
            " [-28.12237 -29.92402]]\n",
            "The result of the backward function should be [[-25.42937 -25.58918]\n",
            " [-23.32164 -23.19959]\n",
            " [-21.11007 -21.02033]\n",
            " [-18.82215 -18.94381]\n",
            " [-16.78523 -16.33951]\n",
            " [-13.42847 -13.51924]\n",
            " [-11.24815 -11.19161]\n",
            " [ -8.88679  -8.96441]\n",
            " [ -6.57374  -6.70985]\n",
            " [ -4.51873  -4.47419]\n",
            " [ -2.44529  -2.51463]\n",
            " [  0.        0.     ]]\n",
            "Your value of beta is: [[-25.42937 -25.58918]\n",
            " [-23.32164 -23.19959]\n",
            " [-21.11007 -21.02033]\n",
            " [-18.82215 -18.94381]\n",
            " [-16.78523 -16.33951]\n",
            " [-13.42847 -13.51924]\n",
            " [-11.24815 -11.19161]\n",
            " [ -8.88679  -8.96441]\n",
            " [ -6.57374  -6.70985]\n",
            " [ -4.51873  -4.47419]\n",
            " [ -2.44529  -2.51463]\n",
            " [  0.        0.     ]]\n",
            "The value of logprob should be: -27.9693\n",
            "Your value of logprob is: -27.96963\n",
            "The value of xi should be: [[[0.64523 0.00601]\n",
            "  [0.34278 0.00598]]\n",
            "\n",
            " [[0.60684 0.38117]\n",
            "  [0.00551 0.00648]]\n",
            "\n",
            " [[0.40595 0.2064 ]\n",
            "  [0.19863 0.18902]]\n",
            "\n",
            " [[0.5718  0.03278]\n",
            "  [0.35711 0.03831]]\n",
            "\n",
            " [[0.02625 0.90266]\n",
            "  [0.00109 0.07   ]]\n",
            "\n",
            " [[0.02482 0.00251]\n",
            "  [0.81777 0.15489]]\n",
            "\n",
            " [[0.59943 0.24316]\n",
            "  [0.08947 0.06793]]\n",
            "\n",
            " [[0.6143  0.07461]\n",
            "  [0.25347 0.05762]]\n",
            "\n",
            " [[0.8357  0.03207]\n",
            "  [0.12337 0.00886]]\n",
            "\n",
            " [[0.69872 0.26034]\n",
            "  [0.02412 0.01682]]\n",
            "\n",
            " [[0.63701 0.08583]\n",
            "  [0.22134 0.05582]]]\n",
            "Your value of xi is: [[[0.64523 0.00601]\n",
            "  [0.34278 0.00598]]\n",
            "\n",
            " [[0.60684 0.38117]\n",
            "  [0.00551 0.00648]]\n",
            "\n",
            " [[0.40595 0.2064 ]\n",
            "  [0.19863 0.18902]]\n",
            "\n",
            " [[0.5718  0.03278]\n",
            "  [0.35711 0.03831]]\n",
            "\n",
            " [[0.02625 0.90266]\n",
            "  [0.00109 0.07   ]]\n",
            "\n",
            " [[0.02482 0.00251]\n",
            "  [0.81777 0.15489]]\n",
            "\n",
            " [[0.59943 0.24316]\n",
            "  [0.08947 0.06793]]\n",
            "\n",
            " [[0.6143  0.07461]\n",
            "  [0.25347 0.05762]]\n",
            "\n",
            " [[0.8357  0.03207]\n",
            "  [0.12337 0.00886]]\n",
            "\n",
            " [[0.69872 0.26034]\n",
            "  [0.02412 0.01682]]\n",
            "\n",
            " [[0.63701 0.08583]\n",
            "  [0.22134 0.05582]]]\n",
            "The value of gamma should be: [[0.65124 0.34876]\n",
            " [0.98802 0.01198]\n",
            " [0.61235 0.38765]\n",
            " [0.60458 0.39542]\n",
            " [0.92891 0.07109]\n",
            " [0.02733 0.97267]\n",
            " [0.8426  0.1574 ]\n",
            " [0.68891 0.31109]\n",
            " [0.86777 0.13223]\n",
            " [0.95906 0.04094]\n",
            " [0.72284 0.27716]\n",
            " [0.85835 0.14165]]\n",
            "Your value of gamma is: [[0.65124 0.34876]\n",
            " [0.98802 0.01198]\n",
            " [0.61235 0.38765]\n",
            " [0.60458 0.39542]\n",
            " [0.92891 0.07109]\n",
            " [0.02733 0.97267]\n",
            " [0.8426  0.1574 ]\n",
            " [0.68891 0.31109]\n",
            " [0.86777 0.13223]\n",
            " [0.95906 0.04094]\n",
            " [0.72284 0.27716]\n",
            " [0.85835 0.14165]]\n",
            "log-likelihood -96.33989919755487\n",
            "log-likelihood -61.837374643034615\n",
            "log-likelihood -59.6590761278549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:107: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:106: RuntimeWarning: divide by zero encountered in log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log-likelihood -58.78006168233149\n",
            "log-likelihood -58.056386229045785\n",
            "log-likelihood -58.047573998672505\n",
            "log-likelihood -58.04756024248872\n",
            "log-likelihood -58.04756014666196\n",
            "log-likelihood -58.04756014303576\n",
            "log-likelihood -58.04756014156317\n",
            "log-likelihood -58.047560140773356\n",
            "log-likelihood -58.04756014034711\n",
            "log-likelihood -58.047560140117014\n",
            "log-likelihood -58.04756013999281\n",
            "log-likelihood -58.047560139925785\n",
            "log-likelihood -58.0475601398896\n",
            "log-likelihood -58.04756013987008\n",
            "log-likelihood -58.04756013985953\n",
            "log-likelihood -58.04756013985383\n",
            "log-likelihood -58.04756013985075\n",
            "hmm.A should be [[0.      1.      0.      0.     ]\n",
            " [0.14122 0.      0.27099 0.58779]\n",
            " [0.20671 0.      0.      0.79329]\n",
            " [0.      0.90909 0.09091 0.     ]]\n",
            "Your implementation has hmm.A to be [[0.      1.      0.      0.     ]\n",
            " [0.14122 0.      0.27099 0.58779]\n",
            " [0.20671 0.      0.      0.79329]\n",
            " [0.      0.90909 0.09091 0.     ]]\n",
            "hmm.B should be [[0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
            "  0.     ]\n",
            " [0.0625  0.      0.      0.5     0.      0.125   0.125   0.      0.125\n",
            "  0.0625 ]\n",
            " [0.      0.20671 0.      0.      0.79329 0.      0.      0.      0.\n",
            "  0.     ]\n",
            " [0.24667 0.      0.57555 0.      0.09556 0.      0.      0.      0.08222\n",
            "  0.     ]]\n",
            "Your implementation has hmm.B to be [[0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
            "  0.     ]\n",
            " [0.0625  0.      0.      0.5     0.      0.125   0.125   0.      0.125\n",
            "  0.0625 ]\n",
            " [0.      0.20671 0.      0.      0.79329 0.      0.      0.      0.\n",
            "  0.     ]\n",
            " [0.24667 0.      0.57555 0.      0.09556 0.      0.      0.      0.08222\n",
            "  0.     ]]\n",
            "hmm.pi should be [1 0 0 0]\n",
            "Your implementation has hmm.pi to be [1. 0. 0. 0.]\n",
            "log-likelihood -63.04097288134068\n",
            "After this test case, hmm.A should either be approximately, [[0 1]\n",
            " [1 0]]\n",
            "This is your current value of hmm.A:  [[0. 1.]\n",
            " [1. 0.]]\n",
            "After this test case, hmm.B should either be approximately, [[0.  0.  0.5 0.5]\n",
            " [0.5 0.5 0.  0. ]]  or it should be  [[0.5 0.5 0.  0. ]\n",
            " [0.  0.  0.5 0.5]]\n",
            "This is your current value of hmm.B:  [[0.      0.      0.52174 0.47826]\n",
            " [0.54167 0.45833 0.      0.     ]]\n",
            "log-likelihood -33.11651892939564\n",
            "log-likelihood -15.726270869914309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:165: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log-likelihood -3.295836866004329\n",
            "log-likelihood -3.295836866004329\n",
            "log-likelihood -3.295836866004329\n",
            "log-likelihood -3.295836866004329\n",
            "log-likelihood -3.295836866004329\n",
            "log-likelihood -3.295836866004329\n",
            "log-likelihood -3.295836866004329\n",
            "log-likelihood -3.295836866004329\n",
            "After this test case, hmm.A should be the identity matrix [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "This is your current value of hmm.A:  [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "After this test case, hmm.B should be some 3 by 3 permutation matrix\n",
            "This is your current value of hmm.B:  [[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nNote: The end_to_end_test is not as robustg due to it using random starts. Try\\nrunning the test case a few times to see if you get a good result at least a few\\ntimes before deciding that your code is buggy.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF-l7WucpCBP"
      },
      "source": [
        "## Training\n",
        "\n",
        "Train a model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTWXUt15pDg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d40eaab-f51e-4e4a-ab9c-96823dcac2ea"
      },
      "source": [
        "tokenizer = lab_util.Tokenizer()\n",
        "tokenizer.fit(train_reviews)\n",
        "train_reviews_tk = tokenizer.tokenize(train_reviews)\n",
        "print(tokenizer.vocab_size)\n",
        "\n",
        "hmm = HMM(num_states=10, num_words=tokenizer.vocab_size)\n",
        "hmm.learn_unsupervised(train_reviews_tk, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2006\n",
            "log-likelihood -2074409.1474417406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiCwE05xqXmI"
      },
      "source": [
        "Let's look at some of the words associated with each hidden state:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXhMoLUFqbn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8062dac-d3f0-4d14-f460-184b1aa7e9b6"
      },
      "source": [
        "for i in range(hmm.num_states):\n",
        "    most_probable = np.argsort(hmm.B[i, :])[-10:]\n",
        "    print(f\"state {i}\")\n",
        "    for o in most_probable:\n",
        "        print(tokenizer.token_to_word[o], hmm.B[i, o])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state 0\n",
            "and 0.016854516606141096\n",
            "is 0.017724502965300922\n",
            ". 0.026651384300688905\n",
            "of 0.02694921618751614\n",
            "the 0.027825377348346086\n",
            "for 0.029802677540205522\n",
            "in 0.03227147728361361\n",
            "a 0.056296898544462376\n",
            "<unk> 0.07534971276229671\n",
            ", 0.07812662306778717\n",
            "\n",
            "state 1\n",
            "is 0.011921706915693707\n",
            "are 0.01268285492414466\n",
            "we 0.01840940369773672\n",
            "these 0.026211606072903668\n",
            "they 0.02751933152885832\n",
            "you 0.03281521312655056\n",
            "br 0.04791835071092612\n",
            "the 0.06341391656783049\n",
            "this 0.08719760773475778\n",
            "i 0.2269775969525636\n",
            "\n",
            "state 2\n",
            "not 0.011473574600711111\n",
            "them 0.013462193786072219\n",
            "a 0.016357856134287602\n",
            "in 0.018014227756421218\n",
            ". 0.024086117056006832\n",
            "it 0.03812742306574631\n",
            ", 0.04838843703935807\n",
            "is 0.050440639736794454\n",
            "to 0.06817857354812536\n",
            "<unk> 0.10679692000362417\n",
            "\n",
            "state 3\n",
            "amazon 0.010151497979271083\n",
            "taste 0.010222165046040755\n",
            "br 0.011636099259617023\n",
            "are 0.01373023219161479\n",
            ", 0.013896582188709882\n",
            "i 0.01663176637915253\n",
            "a 0.019814527105397238\n",
            "<unk> 0.042785985730371554\n",
            ". 0.04500384904417197\n",
            "the 0.04820132835574991\n",
            "\n",
            "state 4\n",
            "not 0.008012838956540928\n",
            "very 0.008672065261373298\n",
            ", 0.009918292733421817\n",
            "other 0.012063893639067983\n",
            "my 0.01445832629407404\n",
            ". 0.01573752826026256\n",
            "and 0.031915146042980375\n",
            "a 0.04423521853872222\n",
            "the 0.07007185051829283\n",
            "<unk> 0.1654670733311943\n",
            "\n",
            "state 5\n",
            "if 0.016237753973320068\n",
            "is 0.016247552279085697\n",
            "are 0.016282502990121676\n",
            "of 0.016648105939826956\n",
            "and 0.01929683171622537\n",
            "a 0.022123775377411645\n",
            "br 0.03854902683095852\n",
            "it 0.04924557047882504\n",
            ". 0.057903703069560074\n",
            "<unk> 0.08928084338081413\n",
            "\n",
            "state 6\n",
            "i 0.017102163836864394\n",
            "but 0.018797851361872977\n",
            "br 0.020450672961435948\n",
            "of 0.022126613696352136\n",
            "! 0.023867504367141492\n",
            "the 0.038649397031371074\n",
            ", 0.0433914379826354\n",
            "and 0.05964781227162704\n",
            "<unk> 0.12811741729753973\n",
            ". 0.1863140495246829\n",
            "\n",
            "state 7\n",
            "a 0.014076385796061925\n",
            "are 0.014786001120353436\n",
            "that 0.016149876957057736\n",
            "br 0.017692391228856456\n",
            "<unk> 0.025632332437672326\n",
            ". 0.02664324952728916\n",
            "product 0.02931139884152984\n",
            "was 0.03177451914432524\n",
            "have 0.03734095986893438\n",
            ", 0.05522500133144559\n",
            "\n",
            "state 8\n",
            "on 0.018540387529711388\n",
            "but 0.020467419261879092\n",
            "a 0.02231616798587614\n",
            "with 0.024302340565065927\n",
            "to 0.03500451933310937\n",
            "of 0.0566271476285619\n",
            ", 0.0596135934309916\n",
            "and 0.06333808187524093\n",
            "the 0.0885085657688675\n",
            ". 0.16342545646785273\n",
            "\n",
            "state 9\n",
            "the 0.010643850041179013\n",
            "a 0.010963793082601625\n",
            "like 0.012070185692441218\n",
            "but 0.012701285822277926\n",
            "to 0.014940194756665606\n",
            "this 0.018793007219777527\n",
            "that 0.020579034263002238\n",
            "not 0.022669302804930097\n",
            "it 0.0715455314636978\n",
            "<unk> 0.14447313267737708\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAQ_PmASwdFz"
      },
      "source": [
        "We can also look at some samples from the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj1eT3s3wgFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a745e4ec-8bbf-4fa7-8431-ddfadf9f9fcb"
      },
      "source": [
        "for i in range(10):\n",
        "    print(tokenizer.de_tokenize([hmm.generate(10)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['yuck personally you are it soda sound cake too all']\n",
            "['purchased br br but are being <unk> <unk> <unk> trying']\n",
            "['in i in my flavoring . brand paying beans design']\n",
            "['this have hot . not of with on this it']\n",
            "['ever lunch but br as low much so but water']\n",
            "['are or . <unk> <unk> day more orange taste for']\n",
            "['only need of across to , the . it flavor']\n",
            "['<unk> wrong problem good not the this i wanted ,']\n",
            "[\"it's night lunch my for different to . grocery that\"]\n",
            "['i egg , like br in the just will <unk>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9Qk9adNr7lQ"
      },
      "source": [
        "Finally, let's repeat the classification experiment from Parts 1 and 2, using the _vector of expected hidden state counts_ as a sentence representation.\n",
        "\n",
        "(Warning! results may not be the same as in earlier versions of this experiment.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL6JQXLJspyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91292a1f-9bd4-450e-da79-67d2cba9269b"
      },
      "source": [
        "def train_model(xs_featurized, ys):\n",
        "  import sklearn.linear_model\n",
        "  model = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
        "  model.fit(xs_featurized, ys)\n",
        "  return model\n",
        "\n",
        "def eval_model(model, xs_featurized, ys):\n",
        "  pred_ys = model.predict(xs_featurized)\n",
        "  print(\"test accuracy\", np.mean(pred_ys == ys))\n",
        "\n",
        "def training_experiment(name, featurizer, n_train):\n",
        "    print(f\"{name} features, {n_train} examples\")\n",
        "    train_xs = np.array([\n",
        "        hmm_featurizer(review) \n",
        "        for review in tokenizer.tokenize(train_reviews[:n_train])\n",
        "    ])\n",
        "    train_ys = train_labels[:n_train]\n",
        "    test_xs = np.array([\n",
        "        hmm_featurizer(review)\n",
        "        for review in tokenizer.tokenize(test_reviews)\n",
        "    ])\n",
        "    test_ys = test_labels\n",
        "    model = train_model(train_xs, train_ys)\n",
        "    eval_model(model, test_xs, test_ys)\n",
        "    print()\n",
        "\n",
        "def hmm_featurizer(review):\n",
        "    _, _, gamma = hmm.forward_backward(review)\n",
        "    return gamma.sum(axis=0)\n",
        "\n",
        "training_experiment(\"hmm\", hmm_featurizer, n_train=3000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hmm features, 3000 examples\n",
            "test accuracy 0.704\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6DI4otm0YHe"
      },
      "source": [
        "## Experiments for Part 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovbrCIUT0NGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd76fdd4-8732-4cd0-8828-b575fb01b5b0"
      },
      "source": [
        "# Part 3 (b)\n",
        "tokenizer = lab_util.Tokenizer()\n",
        "tokenizer.fit(train_reviews)\n",
        "train_reviews_tk = tokenizer.tokenize(train_reviews)\n",
        "print(tokenizer.vocab_size)\n",
        "\n",
        "hmm = HMM(num_states=2, num_words=tokenizer.vocab_size)\n",
        "hmm.learn_unsupervised(train_reviews_tk, 10)\n",
        "print(\"2 states:\\n\")\n",
        "for i in range(hmm.num_states):\n",
        "    most_probable = np.argsort(hmm.B[i, :])[-100:]\n",
        "    print(f\"state {i}\")\n",
        "    for o in most_probable:\n",
        "        print(tokenizer.token_to_word[o], hmm.B[i, o])\n",
        "    print()\n",
        "\n",
        "hmm = HMM(num_states=10, num_words=tokenizer.vocab_size)\n",
        "hmm.learn_unsupervised(train_reviews_tk, 10)\n",
        "print(\"10 states:\\n\")\n",
        "for i in range(hmm.num_states):\n",
        "    most_probable = np.argsort(hmm.B[i, :])[-100:]\n",
        "    print(f\"state {i}\")\n",
        "    for o in most_probable:\n",
        "        print(tokenizer.token_to_word[o], hmm.B[i, o])\n",
        "    print()\n",
        "\n",
        "hmm = HMM(num_states=100, num_words=tokenizer.vocab_size)\n",
        "hmm.learn_unsupervised(train_reviews_tk, 10)\n",
        "print(\"100 states:\\n\")\n",
        "for i in range(hmm.num_states):\n",
        "    most_probable = np.argsort(hmm.B[i, :])[-15:]\n",
        "    print(f\"state {i}\")\n",
        "    for o in most_probable:\n",
        "        print(tokenizer.token_to_word[o], hmm.B[i, o])\n",
        "    print()\n",
        "\n",
        "# Expiriments for Part 3 (c) were simply done in the above\n",
        "# code cell by changing n_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2006\n",
            "log-likelihood -2103005.673700632\n",
            "2 states:\n",
            "\n",
            "state 0\n",
            "real 0.001454877095314458\n",
            "store 0.0014571677142538333\n",
            "use 0.0014611493576798084\n",
            "she 0.001485778678345754\n",
            "which 0.0014986301325533983\n",
            "been 0.0015035094766905775\n",
            "me 0.0015208517252846992\n",
            "about 0.0015320444220478723\n",
            "give 0.0015383977846400955\n",
            "think 0.0015403772999669594\n",
            "your 0.0015523744896875817\n",
            "sugar 0.0015835191246662231\n",
            "amazon 0.0015960533966783569\n",
            "salt 0.0016214953420510866\n",
            "on 0.0016448366563066891\n",
            "don't 0.0016956978202699224\n",
            "want 0.001763551110159697\n",
            "only 0.0017969965734653827\n",
            "there 0.0018018435976250309\n",
            "found 0.001807324298922035\n",
            "good 0.0018170967129075065\n",
            "even 0.0018244918800645947\n",
            "got 0.001850141417173182\n",
            "drink 0.0018553857754342253\n",
            "make 0.001881190736204208\n",
            "great 0.0019006004054356728\n",
            "bought 0.001917242871366712\n",
            "try 0.001940594786815735\n",
            "can 0.001994880330177523\n",
            "what 0.0020356787507069944\n",
            "say 0.002047346579252729\n",
            "less 0.0020850185885147037\n",
            "small 0.00208988484917833\n",
            "something 0.0020928264370810535\n",
            "buy 0.0022203249539339952\n",
            "all 0.0022223495488708184\n",
            "after 0.002230294762013781\n",
            "ordered 0.0022482051284121625\n",
            "food 0.0022837650518657657\n",
            "will 0.002338975693699619\n",
            "time 0.0023716504241313697\n",
            "not 0.0024309777241861507\n",
            "much 0.002442756860425845\n",
            "be 0.002500646209771503\n",
            "tried 0.002503825178648898\n",
            "bit 0.0025178528737367133\n",
            "are 0.0025669365087669085\n",
            "by 0.0026133629408230225\n",
            "than 0.00265792179054803\n",
            "at 0.0027673573036793176\n",
            "some 0.0027718742520420957\n",
            "do 0.002884567805749887\n",
            "one 0.0029133662512138454\n",
            "very 0.002986962187626677\n",
            "from 0.002989095613544886\n",
            "used 0.0030578761974135965\n",
            "it's 0.003135849911885672\n",
            "with 0.003176168558533643\n",
            "just 0.003225200531856621\n",
            "i've 0.0032323133384441604\n",
            "love 0.0032464206698814987\n",
            "taste 0.0032557834224469892\n",
            "i'm 0.003397183998928019\n",
            "them 0.0034418755434609235\n",
            "coffee 0.0034570728791657075\n",
            "bag 0.003555659939044905\n",
            "that 0.003833271204238591\n",
            "well 0.0039359396374664965\n",
            "too 0.004215349085440352\n",
            "when 0.004955731192694642\n",
            "we 0.005132024804521173\n",
            "were 0.005290991128186131\n",
            "for 0.0053103017910680434\n",
            "so 0.0053613343857859385\n",
            "you 0.005414886251373844\n",
            "chips 0.00621703115364703\n",
            "had 0.0068770277546442975\n",
            "! 0.007344466399176295\n",
            "br 0.008413173642886964\n",
            "is 0.008431110631444746\n",
            "they 0.008590929111321933\n",
            "if 0.009072953728733771\n",
            "was 0.009292513500275362\n",
            "of 0.011167202946216393\n",
            "my 0.011960673014423242\n",
            "and 0.011985608155255786\n",
            "have 0.012479085528190735\n",
            "as 0.012885262630497085\n",
            "these 0.013825044766271005\n",
            "a 0.019591855110370145\n",
            "but 0.019849118707177815\n",
            "it 0.02164829252533926\n",
            "this 0.02480390771706738\n",
            "to 0.03030147276340822\n",
            "<unk> 0.030732313113532\n",
            "in 0.03139494338459317\n",
            ", 0.031735547153450915\n",
            ". 0.03548578599887757\n",
            "the 0.041122516079973234\n",
            "i 0.07080355885979289\n",
            "\n",
            "state 1\n",
            "3 0.0012801872406854409\n",
            "cup 0.001291097490399357\n",
            "mix 0.0012973291946206664\n",
            "even 0.0013136923137763072\n",
            "when 0.001318356621368622\n",
            "eat 0.0013243612477626704\n",
            "then 0.0013407024806116978\n",
            "their 0.0013697019254183388\n",
            "now 0.0014078542750829471\n",
            "use 0.0014574993587466098\n",
            "again 0.0014697491457605473\n",
            "what 0.0014892006731053943\n",
            "little 0.0015315074347494106\n",
            "box 0.0015385997965071444\n",
            "chips 0.0015498919839387186\n",
            "juice 0.0015523642823337554\n",
            "buy 0.0015532742116063881\n",
            "some 0.0015796126500609011\n",
            "2 0.0015937200722521184\n",
            "sugar 0.0015939361394844218\n",
            "love 0.0015990385241842853\n",
            "any 0.001638815370328519\n",
            "which 0.0016499892761414883\n",
            "much 0.0017019492313733828\n",
            "find 0.0017023883918935077\n",
            "there 0.0017283795689358192\n",
            "flavors 0.0017437000966716513\n",
            "water 0.0017726460263581584\n",
            "tea 0.0018068542745420654\n",
            "price 0.0018536153075176447\n",
            "your 0.0018563855763208776\n",
            "food 0.0018682466517237896\n",
            "as 0.001880337070849148\n",
            "coffee 0.0018987050480981824\n",
            "am 0.0019095119889359694\n",
            "up 0.0019439736556619062\n",
            "because 0.001981326533788889\n",
            "only 0.001989245644557135\n",
            "better 0.002024054725360243\n",
            "an 0.0020367556640224645\n",
            "? 0.0020479375411923424\n",
            "don't 0.002090720919981413\n",
            "amazon 0.002137546214916472\n",
            "about 0.0021622383039765145\n",
            "also 0.0022073588134918403\n",
            "than 0.0023550540918415522\n",
            "but 0.0023735474968395154\n",
            "get 0.002376080431973831\n",
            "really 0.002470447348698417\n",
            "will 0.0025264835102691728\n",
            "other 0.0026125945633420143\n",
            "it's 0.0026691899659406185\n",
            "from 0.0027327660592246132\n",
            "out 0.002784647432905793\n",
            "has 0.002909081953629112\n",
            "no 0.0029197061283968754\n",
            "great 0.0030126239018255685\n",
            "me 0.0030725572206974873\n",
            "have 0.0030947882523205054\n",
            "very 0.003180910950441194\n",
            "one 0.0032262699533050472\n",
            "just 0.003311383633233411\n",
            "can 0.003340040256377639\n",
            "would 0.0033783137882629033\n",
            "more 0.0035190707677777073\n",
            "at 0.003774348931902817\n",
            "all 0.0038419070946842052\n",
            "taste 0.004008129946138417\n",
            "flavor 0.004424761914765549\n",
            "product 0.004480188812757697\n",
            "so 0.004543275024846762\n",
            "be 0.004573089989774018\n",
            "or 0.004634389477841993\n",
            "good 0.004646492397960944\n",
            "them 0.004739543899890539\n",
            "they 0.0049865729178896505\n",
            "was 0.005556553598206395\n",
            "my 0.0056549232506196215\n",
            "on 0.006602207001546216\n",
            "like 0.006625962071121217\n",
            "this 0.006725372647664062\n",
            "you 0.0070501205843002705\n",
            "! 0.0072369779808194295\n",
            "with 0.008484642763826798\n",
            "are 0.008878680600214258\n",
            "i 0.009992778519643745\n",
            "that 0.01006678179340129\n",
            "not 0.01031093419685607\n",
            "for 0.012179450812611963\n",
            "to 0.013429566833667484\n",
            "it 0.014619107615028618\n",
            "is 0.015593763166858302\n",
            "br 0.016577285730340088\n",
            "of 0.017939019347795772\n",
            "a 0.024081181205083152\n",
            "and 0.03019293646324601\n",
            "the 0.03563095755130696\n",
            ", 0.03614174430755836\n",
            ". 0.07522560119776964\n",
            "<unk> 0.10101784717202363\n",
            "\n",
            "log-likelihood -2068653.3920296084\n",
            "10 states:\n",
            "\n",
            "state 0\n",
            "off 0.0013908260992285643\n",
            "3 0.0014264090845254463\n",
            "need 0.0014368919600801949\n",
            "am 0.0014435558721508227\n",
            "we 0.0014441920681768057\n",
            "chocolate 0.0014652698580456221\n",
            "; 0.0014815848472063274\n",
            "orange 0.0014914421498231417\n",
            "least 0.0015067090964664602\n",
            "it's 0.0015150239381847715\n",
            "purchased 0.0015194321523784929\n",
            "deal 0.0015327297806251416\n",
            "products 0.0015434056062469713\n",
            "other 0.0015534234731177177\n",
            "too 0.0015733616503541248\n",
            "dog 0.0015763411339057955\n",
            "down 0.0016173969394487455\n",
            "my 0.0016184736002079142\n",
            "received 0.0016276116801861296\n",
            "quality 0.0016339502582074297\n",
            "again 0.0016461147383937727\n",
            "through 0.0016643376354884608\n",
            "had 0.0017138427922956242\n",
            "your 0.0017425129666365047\n",
            "think 0.0018405939352673301\n",
            "put 0.0018776730696419871\n",
            "may 0.0019002042414223378\n",
            "got 0.0019075163512424064\n",
            "worth 0.0019308492306021334\n",
            "by 0.0019957790176950312\n",
            "found 0.0019977527918835745\n",
            "did 0.002051020342893984\n",
            "than 0.0021404993903786306\n",
            "i 0.00216384487625957\n",
            "so 0.002180673417752051\n",
            "at 0.0022118679722178953\n",
            "more 0.0022428773472733337\n",
            "try 0.00225332627487561\n",
            "order 0.002259339423551769\n",
            "an 0.002285096279914597\n",
            "do 0.002310881862658334\n",
            "give 0.0023227284965354595\n",
            "because 0.002393469565676559\n",
            "ordered 0.0024144393912739885\n",
            "any 0.002458179985769698\n",
            "over 0.0024744914386362446\n",
            "2 0.0026334028430246266\n",
            "only 0.002644541610163736\n",
            "could 0.0026463634374219087\n",
            "bought 0.0026470294172128463\n",
            "brand 0.0026672371064971135\n",
            "how 0.0026874740882677725\n",
            "amazon 0.0028231667149187286\n",
            "be 0.002866071111969521\n",
            "good 0.0029124432528087945\n",
            "as 0.0029494439062302423\n",
            "first 0.0029599007145718493\n",
            "not 0.003014727919524869\n",
            "used 0.0031261380934535774\n",
            "favorite 0.003179196899676038\n",
            "these 0.003252909813514095\n",
            "me 0.0032698198024997374\n",
            "use 0.003356923614703917\n",
            "just 0.0034672635885233966\n",
            "want 0.003925383721379943\n",
            "out 0.00407625761690384\n",
            "a 0.004231700063084948\n",
            "buy 0.004248432052289202\n",
            "or 0.004328457760248121\n",
            "them 0.004845759450624425\n",
            "can 0.004845953861622073\n",
            "they 0.005009499936961639\n",
            "product 0.005063418336282376\n",
            "this 0.005071329793715745\n",
            "about 0.005203298510012539\n",
            "flavor 0.005353982986606421\n",
            "like 0.005360091435050797\n",
            "that 0.00590966635401436\n",
            "tried 0.006220301919472926\n",
            "will 0.006314711487502288\n",
            "you 0.006412227947918363\n",
            "chips 0.007546814027055598\n",
            "! 0.009340696657100425\n",
            "was 0.009401475507364003\n",
            "is 0.010712849185937453\n",
            "with 0.011102328391093317\n",
            "for 0.011619710316731554\n",
            "it 0.011945739920490773\n",
            "in 0.012535417825283654\n",
            ", 0.013135210205094455\n",
            "are 0.013393473549804285\n",
            "br 0.017489090141881845\n",
            "on 0.017747737268886322\n",
            "have 0.018257591558546882\n",
            "the 0.020589997599935416\n",
            "and 0.025170389560483366\n",
            "of 0.032367922744489304\n",
            "to 0.0587106173526524\n",
            "<unk> 0.06109720659004243\n",
            ". 0.11591222119938754\n",
            "\n",
            "state 1\n",
            "beans 0.0012186103190096722\n",
            "green 0.001219536653243835\n",
            "even 0.0012485519439765667\n",
            "again 0.001271272873256396\n",
            "like 0.0012764301035771799\n",
            "time 0.001281049322001508\n",
            "when 0.0013068584571483634\n",
            "syrup 0.0013132441872407048\n",
            "though 0.0013163396794002747\n",
            "since 0.0013278908227759825\n",
            "make 0.0014293699578936923\n",
            "expensive 0.001445751944295713\n",
            "no 0.0014916202627454618\n",
            "well 0.001495811653097487\n",
            "by 0.0015047502500914467\n",
            "try 0.00155590485060002\n",
            "same 0.0015734025390593672\n",
            "cream 0.0015851340644516068\n",
            "get 0.001620133562717325\n",
            "milk 0.001633256977235723\n",
            "taste 0.0016916080697964202\n",
            "vitamin 0.0017034525584452358\n",
            "has 0.0017074468707012995\n",
            "organic 0.0017473481061212757\n",
            "4 0.0017615504227919184\n",
            "full 0.0017661602174536715\n",
            "all 0.0017709695966898252\n",
            "bag 0.0017800625544989838\n",
            "fat 0.001786977103183549\n",
            "about 0.001797229186556118\n",
            "he 0.0018092288548957052\n",
            "oil 0.0018372350400166749\n",
            "in 0.001845811492683629\n",
            "etc 0.0018641181545386808\n",
            "size 0.00196693847037982\n",
            "flavor 0.0019834345603670068\n",
            "i'm 0.0019899861409491933\n",
            "juice 0.002004072408788612\n",
            "flavors 0.002012915421641424\n",
            "just 0.002033770164883502\n",
            "? 0.0020527328375615937\n",
            "coffee 0.002054317687386332\n",
            "drink 0.002109074601864742\n",
            "food 0.0021180746290551736\n",
            "3 0.0021232737736491783\n",
            "sweet 0.0021310500268964952\n",
            "much 0.002135446568985933\n",
            "more 0.002150472079942872\n",
            "eat 0.002164904814678579\n",
            "gp 0.0021997806946409217\n",
            "grocery 0.002269307087619127\n",
            "me 0.002321796143517138\n",
            "1 0.00232971762068204\n",
            "were 0.00237275567331952\n",
            "mix 0.002410505938139483\n",
            "corn 0.0024159234754669357\n",
            "use 0.0025499760973466574\n",
            "water 0.0025707382326125585\n",
            "price 0.0025832816534792605\n",
            "of 0.0026699699922996547\n",
            "these 0.0026777194389576917\n",
            "local 0.0027774557989134426\n",
            "com 0.0028239121646752127\n",
            "or 0.002891588628208452\n",
            "because 0.0029070274502737505\n",
            "we 0.002949064365164859\n",
            "only 0.0030055984133886765\n",
            "can 0.0030658426131817975\n",
            "have 0.0030961772195003965\n",
            "salt 0.0032217245932304743\n",
            "2 0.003333843410724532\n",
            "not 0.0033491130472487977\n",
            "on 0.0034039552374368278\n",
            "product 0.0034421764732486754\n",
            "one 0.0034557994035788633\n",
            "store 0.0035256959354261993\n",
            "so 0.003937687879104775\n",
            "which 0.003990362869446561\n",
            "very 0.004336130116227546\n",
            "! 0.004344250396876524\n",
            "from 0.004350113144259883\n",
            "that 0.005100132679161265\n",
            "then 0.005336237469175988\n",
            "too 0.005861956641499555\n",
            "for 0.0058771300634270236\n",
            "but 0.006170037618927439\n",
            "are 0.006240921917710494\n",
            "with 0.006312321594474253\n",
            "to 0.007009956521340481\n",
            "is 0.00765494323633882\n",
            "my 0.010096405791754413\n",
            "i 0.010195738708590146\n",
            "a 0.019471382823606682\n",
            "it 0.025747200519692415\n",
            "this 0.028538831529987815\n",
            ". 0.04184810128932698\n",
            "the 0.054420298031571925\n",
            ", 0.06458555617914152\n",
            "and 0.07028015811703801\n",
            "<unk> 0.12812576456118072\n",
            "\n",
            "state 2\n",
            "calories 0.0014044270636581091\n",
            "give 0.0014208323120373622\n",
            "tea 0.0014218691788444873\n",
            "recommend 0.001443398635094145\n",
            "cup 0.0014539303180788631\n",
            "order 0.0014585986452361423\n",
            "up 0.001461082165822135\n",
            "still 0.001467385749736719\n",
            "what 0.0014711574094924047\n",
            "bought 0.0014764301692836092\n",
            "mix 0.0014858939127716363\n",
            "over 0.0015212095558446198\n",
            "now 0.0015406747325278005\n",
            "these 0.0015531927606008168\n",
            "? 0.0015547988184375565\n",
            "amazon 0.0015886865291500787\n",
            "i'm 0.0015916078215606666\n",
            "after 0.0015924992968275491\n",
            "k 0.0016008043882305898\n",
            "regular 0.001611474188560592\n",
            "also 0.0016951483757153029\n",
            "no 0.0017381455118113084\n",
            "could 0.0017591296304838905\n",
            "made 0.001767085480289401\n",
            "make 0.001788274023406764\n",
            "about 0.0018566582110938067\n",
            "because 0.0018733639101338995\n",
            "sure 0.0019549717576396435\n",
            "just 0.0019741157389125074\n",
            "pack 0.001982920001159596\n",
            "some 0.0019850052175998225\n",
            "would 0.0020104698436499697\n",
            "or 0.0020339404917493874\n",
            "do 0.0020354543096018545\n",
            "by 0.0020477296332013675\n",
            "little 0.002099082576752718\n",
            "chips 0.0021379143430320323\n",
            "from 0.0021509262682817406\n",
            "it's 0.0021971419363190294\n",
            "drink 0.002248892860634009\n",
            "this 0.0022498871320032416\n",
            "even 0.002280892112847623\n",
            "we 0.0023808879201303893\n",
            "my 0.002497119658960059\n",
            "find 0.0025442797495699144\n",
            "bags 0.0025738564792402744\n",
            "before 0.0025748044314242557\n",
            "think 0.0025820414553657336\n",
            "more 0.002819939598546304\n",
            "can 0.0028921056012535876\n",
            "water 0.002947469324502126\n",
            "all 0.0029553830924363106\n",
            "time 0.0030441343615597695\n",
            "buy 0.003215348662403738\n",
            "box 0.00322555645418077\n",
            "best 0.003275455735762079\n",
            "food 0.003423401282342886\n",
            "when 0.0035064413227697115\n",
            "will 0.003773519235992515\n",
            "flavor 0.003894670660808581\n",
            "only 0.003942103318015186\n",
            "taste 0.00408424327093404\n",
            "other 0.004121081565862731\n",
            "me 0.004176692318435631\n",
            "were 0.004236002172922839\n",
            "has 0.004296359450882762\n",
            "coffee 0.004580961067551559\n",
            "on 0.004750100682797681\n",
            "was 0.004800781699041178\n",
            "be 0.00494499990721975\n",
            "get 0.005123485786482509\n",
            "had 0.005307501326563356\n",
            "so 0.005390671176199461\n",
            "one 0.005638920163197829\n",
            "but 0.006431623464982626\n",
            "at 0.006600508170202938\n",
            "as 0.006974809458985338\n",
            "they 0.007093339087493504\n",
            "good 0.007487670450544932\n",
            "have 0.007872757257130856\n",
            "br 0.009121033597087616\n",
            "you 0.009382544021403892\n",
            "and 0.01005917227671954\n",
            "in 0.011208976058022558\n",
            "like 0.012060553075509557\n",
            "the 0.012371240318684194\n",
            "with 0.01264444768159279\n",
            "i 0.015603606175507954\n",
            "are 0.016377057701686945\n",
            "it 0.016974364277914128\n",
            "that 0.017506854097585126\n",
            "is 0.018109437974407904\n",
            "for 0.018966857885704645\n",
            "! 0.01910400985083606\n",
            "<unk> 0.020745674398631155\n",
            "to 0.023224729173563004\n",
            "of 0.02639957766580779\n",
            "a 0.030562908310430126\n",
            ", 0.07677515926473294\n",
            ". 0.08041830933985478\n",
            "\n",
            "state 3\n",
            "she 0.0014333629592884216\n",
            "probably 0.0014336527846276527\n",
            "especially 0.00143972134300302\n",
            "any 0.0014579582634195697\n",
            "as 0.001471089342140356\n",
            "or 0.0014901640163699683\n",
            "recommend 0.0014959434711918553\n",
            "purchased 0.0015267430022710116\n",
            "didn't 0.0015331827979574299\n",
            "out 0.0015774626440097591\n",
            "have 0.0016014037164655867\n",
            "while 0.001627454044938517\n",
            "food 0.001641903847305043\n",
            "could 0.0016474308515266403\n",
            "pretty 0.001665444801902361\n",
            "am 0.0016726025361532097\n",
            "had 0.0016732308256563572\n",
            "product 0.001685737584226514\n",
            "definitely 0.001685789017466026\n",
            "something 0.001697054371575182\n",
            "little 0.0017250637263140068\n",
            "know 0.0017661096127021732\n",
            "your 0.0017739108239943784\n",
            "their 0.0018029268191271102\n",
            "found 0.0018030934232116885\n",
            "at 0.0018081555107980472\n",
            "cups 0.0018561276219644701\n",
            "those 0.0018793289400937847\n",
            "can't 0.0018969185940521562\n",
            "try 0.0019117200761997561\n",
            "? 0.0020381941677525286\n",
            "first 0.0020674940254602476\n",
            "than 0.002093937891437301\n",
            "since 0.002165098939778681\n",
            "highly 0.0022455264572550275\n",
            "got 0.0022852110788847265\n",
            "cup 0.002320218599394645\n",
            "chips 0.002338125606523759\n",
            "flavor 0.0023468994469141814\n",
            "few 0.0023738305635159747\n",
            "get 0.002386012173701655\n",
            "tried 0.002431091869341854\n",
            "http 0.0024617517492884333\n",
            "do 0.002464107823477588\n",
            "healthy 0.0024828106216814947\n",
            "great 0.002535305279036007\n",
            "i'm 0.0027163085557332578\n",
            "from 0.0027311499046961565\n",
            "big 0.002819056184864838\n",
            "good 0.0029370601585642885\n",
            "about 0.0029679915581596536\n",
            "what 0.003002966526054988\n",
            "because 0.0030425942523611875\n",
            "some 0.0030995065189002823\n",
            "would 0.0031216315838734476\n",
            "after 0.003161397654115656\n",
            "even 0.0031986774279903008\n",
            "them 0.003346562235039376\n",
            "we 0.003541428240731288\n",
            "be 0.003944507953423556\n",
            "just 0.004458354323032101\n",
            "like 0.004556590002680047\n",
            "it 0.004610511607687643\n",
            "bit 0.004758949265585275\n",
            "an 0.005129398309440134\n",
            "love 0.005303929363624998\n",
            "one 0.005319816051763528\n",
            "all 0.005321208437739282\n",
            ", 0.005708830939328248\n",
            "really 0.005930616019085607\n",
            "are 0.006210053479954403\n",
            "very 0.006428803867771797\n",
            "don't 0.006698871786821068\n",
            "no 0.006774532152414452\n",
            "! 0.006887643656889778\n",
            "br 0.007207449952530699\n",
            "is 0.007612704285372133\n",
            "with 0.008685734027026357\n",
            "was 0.008853568485075267\n",
            "when 0.008950369129576587\n",
            "in 0.009110312476767269\n",
            "they 0.009338583752941481\n",
            "it's 0.0108910815900188\n",
            "for 0.01107387868600182\n",
            "so 0.011876903130681338\n",
            "to 0.012042900559718291\n",
            "if 0.012488940005299154\n",
            "<unk> 0.012587553614942501\n",
            "that 0.012821644039902326\n",
            "this 0.013703203200582742\n",
            "these 0.014798836737017701\n",
            "not 0.018404378646822032\n",
            "my 0.019190352848562516\n",
            "but 0.02331992073283642\n",
            "and 0.02479954301258901\n",
            "of 0.026622718860386547\n",
            ". 0.03583650042944322\n",
            "a 0.06326846753403881\n",
            "i 0.0640185735482895\n",
            "the 0.07404822387732268\n",
            "\n",
            "state 4\n",
            "case 0.0011112486912366899\n",
            "ingredients 0.0011320448393697593\n",
            "two 0.0011391109360411216\n",
            "husband 0.001153013999532689\n",
            "maybe 0.0011761431483134615\n",
            "1 0.001177116974300357\n",
            "chocolate 0.0011858121436999845\n",
            "any 0.001205014894576865\n",
            "grocery 0.0012193713443827171\n",
            "healthy 0.0012524862544396318\n",
            "try 0.0012540542358526446\n",
            "texture 0.0012656743086956286\n",
            "still 0.0012668361821874545\n",
            "favorite 0.0012762234139692685\n",
            "box 0.0013006229252604691\n",
            "no 0.0013256576062537272\n",
            "little 0.001366058824112927\n",
            "great 0.0013746399410582131\n",
            "5 0.001377871794840806\n",
            "most 0.0013880624061651326\n",
            "pack 0.001389200025180321\n",
            "these 0.0014026058523768468\n",
            "out 0.0014177712380615988\n",
            "some 0.001450810670476712\n",
            "does 0.0014920953441025482\n",
            "juice 0.0015453497551896089\n",
            "bag 0.0015676205971301886\n",
            "per 0.0015739816865005928\n",
            "even 0.0015807813441987282\n",
            "without 0.00158736809085579\n",
            "flavor 0.001596449386440801\n",
            "the 0.00160203249457435\n",
            "food 0.0016100116460387426\n",
            "fresh 0.0016437694180697507\n",
            "this 0.0016830523993886129\n",
            "water 0.0016896745464648711\n",
            "first 0.0017021871012120168\n",
            "if 0.001789605580061483\n",
            "on 0.0018126117502206623\n",
            "were 0.0018194560832513274\n",
            "from 0.0018442098170670161\n",
            "because 0.0019142085694875454\n",
            "old 0.001929323360366146\n",
            "best 0.001966946967906137\n",
            "same 0.0019716713826746705\n",
            "small 0.0019731047939191165\n",
            "bags 0.002012660362256688\n",
            "sweet 0.0020640649821737334\n",
            "salt 0.002084135756415257\n",
            "tea 0.0020870961631674536\n",
            "me 0.0021366347514127455\n",
            "less 0.002147419253863354\n",
            "price 0.002175272467085582\n",
            "up 0.002197620382701206\n",
            "at 0.0022158579113075935\n",
            "would 0.002218456081279924\n",
            "much 0.00228757889808048\n",
            "you 0.0023119265748331825\n",
            "them 0.0024020276657473623\n",
            "better 0.002435596416000053\n",
            "one 0.0024428533983063046\n",
            "time 0.0024442396773228137\n",
            "only 0.002446480112775193\n",
            "have 0.0025554419305260055\n",
            "free 0.0026323810854803576\n",
            "has 0.0027465676146121542\n",
            "more 0.002795065093277433\n",
            "or 0.00282432554290403\n",
            "by 0.003942727652903382\n",
            "my 0.004037057122103228\n",
            "an 0.0040699888417423434\n",
            "all 0.004154302144897506\n",
            "with 0.004390287826573032\n",
            "not 0.004397324429290399\n",
            "so 0.004552499794250503\n",
            "product 0.004704672555062278\n",
            "i 0.004736518090756622\n",
            "too 0.005210441938606939\n",
            "are 0.005620687109247091\n",
            "taste 0.005849708905752101\n",
            "than 0.006171874124426778\n",
            "but 0.006194348725489657\n",
            "a 0.006397714924124384\n",
            "they 0.006846140547991437\n",
            "like 0.007142654568086187\n",
            "br 0.009375007430456798\n",
            "! 0.009785322772256634\n",
            "that 0.0099118248224981\n",
            "was 0.010379615300319979\n",
            "in 0.011618228014009222\n",
            "it 0.012696736380381754\n",
            "for 0.013449868124843478\n",
            "as 0.013563377055383317\n",
            "to 0.01576048538295728\n",
            "is 0.023447922329702338\n",
            "and 0.030514109803990747\n",
            "of 0.03386540903536276\n",
            ", 0.08000616108326816\n",
            ". 0.09341439381721597\n",
            "<unk> 0.1588766228712318\n",
            "\n",
            "state 5\n",
            "find 0.0016414675808912279\n",
            "snack 0.0016602786794575122\n",
            "fruit 0.0016803853186482822\n",
            "another 0.0017157453362858005\n",
            "also 0.0017298174119595533\n",
            "which 0.0017314144682585371\n",
            "added 0.00173450774058511\n",
            "here 0.0017532935816460134\n",
            "cup 0.0017561319807410894\n",
            "tasted 0.0017806390602351644\n",
            "know 0.001784314147437399\n",
            "most 0.0018040702218326183\n",
            "can't 0.0018399672080625948\n",
            "many 0.0018659891111011727\n",
            "like 0.0018753475341780595\n",
            "two 0.0018808328910722629\n",
            "even 0.0018988111121670138\n",
            "order 0.0019037765682238985\n",
            "want 0.0019050206319349869\n",
            "best 0.0019334354475606184\n",
            "love 0.0019530194727728982\n",
            "only 0.0019627611837187515\n",
            "way 0.001986107245740966\n",
            "go 0.0020559068975977723\n",
            "do 0.0020708196454980177\n",
            "regular 0.002073986772915112\n",
            "if 0.002223180681073917\n",
            "or 0.002259268157611285\n",
            "something 0.0022624570101506523\n",
            "coffee 0.0022802724614529976\n",
            "out 0.002305351885875083\n",
            "what 0.002308770290413463\n",
            "this 0.0024229892267936684\n",
            "was 0.002464788054412253\n",
            "little 0.0024969700854933293\n",
            "flavors 0.002504503932252239\n",
            "up 0.0025718006964141867\n",
            "much 0.0026196278296449272\n",
            "it's 0.0026304653721210152\n",
            "say 0.0026522372303752514\n",
            "but 0.0027008466204684395\n",
            "your 0.0027345094509267317\n",
            "about 0.0027443279463126007\n",
            "food 0.0028591672844492243\n",
            "now 0.0029315309050941996\n",
            "so 0.002934028987950196\n",
            "their 0.0029435795278773508\n",
            "bag 0.0030190321468373106\n",
            "them 0.0030492833577372364\n",
            "been 0.003081058942539904\n",
            "and 0.003218419416536182\n",
            "great 0.0032291532003763147\n",
            "tea 0.003270016540299096\n",
            "an 0.0033649097692829443\n",
            "will 0.0034940646077715595\n",
            "no 0.0035563034763821063\n",
            "at 0.0036622387615515956\n",
            "on 0.0037200293866386353\n",
            "some 0.0037710957800320393\n",
            "buy 0.0039294777397657485\n",
            "amazon 0.00402179603332232\n",
            "other 0.0041262255598199125\n",
            "were 0.0043837021023116814\n",
            "there 0.004477085896812056\n",
            "chips 0.004525349685064706\n",
            "good 0.00453969646770804\n",
            "with 0.004635007469604053\n",
            "have 0.004730774718404078\n",
            "that 0.004740799969081438\n",
            "me 0.004794365059689445\n",
            "are 0.0048254066922702645\n",
            "more 0.005042561449875367\n",
            "would 0.005240143661971045\n",
            "you 0.005294258853545385\n",
            "as 0.005367601498177222\n",
            "can 0.00553225944739078\n",
            "just 0.0056331247731894905\n",
            "all 0.005985680398064349\n",
            "really 0.005986184237962585\n",
            "they 0.006089860400328948\n",
            "in 0.006233021611414282\n",
            "flavor 0.0064417725576430464\n",
            "for 0.007151180967169508\n",
            "very 0.00749723868509544\n",
            "taste 0.008097244535847073\n",
            "had 0.008136931637399442\n",
            "is 0.008269673776067982\n",
            "to 0.008305173829965339\n",
            "! 0.00870856537492398\n",
            "be 0.009372152944153625\n",
            "not 0.011428175783032825\n",
            ", 0.011784637558598111\n",
            "of 0.011824377362882879\n",
            "my 0.012913564750258398\n",
            "it 0.017423604267647788\n",
            "br 0.026733773662904647\n",
            "a 0.031774271721851904\n",
            ". 0.034768415492899836\n",
            "<unk> 0.0728039547616994\n",
            "the 0.08545066645424808\n",
            "\n",
            "state 6\n",
            "pack 0.0015088891829534916\n",
            "4 0.0015187719377411102\n",
            "juice 0.0015352367151201527\n",
            "she 0.0015404075596641199\n",
            "work 0.001568518167474575\n",
            "organic 0.0015793213091707886\n",
            "enough 0.0016377968525975676\n",
            "high 0.0016410879227035475\n",
            "soda 0.0016470514068212014\n",
            "still 0.0016640203370116519\n",
            "however 0.001668656998994066\n",
            "many 0.0017000671077178587\n",
            "tasty 0.0017090065587005638\n",
            "looking 0.0017303218078722207\n",
            "way 0.0017463808527049714\n",
            "same 0.0017639736113851223\n",
            "two 0.0017648411807818301\n",
            "dog 0.0017991195280796463\n",
            "drink 0.001800964879974893\n",
            "natural 0.0018175925690604594\n",
            "bad 0.0018209118462714211\n",
            "? 0.001853466366039881\n",
            "3 0.001866384338926676\n",
            "now 0.0019232272844350946\n",
            "go 0.0019562176336834635\n",
            "free 0.0019816972369128176\n",
            "time 0.001987177817988618\n",
            "great 0.0020564955801274615\n",
            "very 0.002097387966434695\n",
            "shipping 0.002111992033117206\n",
            "eat 0.0021517092679497344\n",
            "any 0.0021968572588759692\n",
            "5 0.0022038718396965883\n",
            "water 0.0022290600293687845\n",
            "was 0.002231617443564308\n",
            "one 0.0022381593281074167\n",
            "1 0.002251228085640494\n",
            "our 0.002311239594119209\n",
            "than 0.002403388934263235\n",
            "with 0.0024456181858880854\n",
            "much 0.0025346462303319143\n",
            "orange 0.0025512513752326597\n",
            "had 0.002561750880818814\n",
            "all 0.0026078992183575823\n",
            "hot 0.002665029659196173\n",
            "up 0.002685745542911483\n",
            "bag 0.0027026830596010554\n",
            "ingredients 0.002713852106445672\n",
            "were 0.0027272535682437305\n",
            "is 0.0027286906348553985\n",
            ", 0.002735979803900418\n",
            "flavors 0.0027815696686238765\n",
            "again 0.0028608121472104755\n",
            "or 0.00287899581753702\n",
            "their 0.003111703335248403\n",
            "box 0.0031168362463465864\n",
            "don't 0.003120346904790122\n",
            "just 0.003227310165394521\n",
            "price 0.0032516601179546378\n",
            "also 0.0032853954312674198\n",
            "out 0.0032950519106499728\n",
            "better 0.0032969501352723366\n",
            "have 0.0033386196073192623\n",
            "like 0.0034073708489619253\n",
            "good 0.003440994331566106\n",
            "product 0.0035783604569268423\n",
            "are 0.004353790374181205\n",
            "some 0.004410232683370791\n",
            "there 0.004435013456866969\n",
            "me 0.004478618331953059\n",
            "more 0.004719105749152371\n",
            "at 0.004744861237817775\n",
            "on 0.004868783957061732\n",
            "amazon 0.005132673554916798\n",
            "well 0.005393341791976083\n",
            "this 0.005467203462066296\n",
            "taste 0.005719336174287467\n",
            "flavor 0.00590053603777172\n",
            "other 0.005945388831185101\n",
            "your 0.006161043210021809\n",
            "coffee 0.0063183472609368435\n",
            "these 0.006443926838615537\n",
            "chips 0.007252258073729502\n",
            "in 0.007415430301732972\n",
            "for 0.00789342498493484\n",
            "sugar 0.008624468170637858\n",
            "them 0.009244849460588175\n",
            "they 0.009313413581943226\n",
            "you 0.010584465381774363\n",
            "and 0.010830688744046659\n",
            "that 0.010975225517186283\n",
            "i 0.013011285198034767\n",
            "my 0.01362090002541658\n",
            "not 0.014521277641349981\n",
            "to 0.022187514894915855\n",
            "it 0.025808290507210414\n",
            "br 0.028197063729597825\n",
            ". 0.04622510924852191\n",
            "the 0.05912994525660776\n",
            "<unk> 0.08875618741977288\n",
            "\n",
            "state 7\n",
            "there 0.0012516678733066687\n",
            "k 0.0012647278361880827\n",
            "by 0.0012647632325448609\n",
            "line 0.0012849323972680233\n",
            "; 0.0013039144613107019\n",
            "ever 0.00130840305910919\n",
            "it 0.001313603707949248\n",
            "own 0.001353835101422093\n",
            "if 0.0013726562618250671\n",
            "isn't 0.0014009289221149424\n",
            "tangerine 0.00140392625385531\n",
            "add 0.0014060414322144884\n",
            "only 0.0014636989348269641\n",
            "every 0.0015043765923917435\n",
            "chocolate 0.0015619093654459927\n",
            "water 0.0015801742315721726\n",
            "tastes 0.0015953753849547584\n",
            "again 0.001601901507966487\n",
            "per 0.0016050915521318263\n",
            "drink 0.0016202514834163123\n",
            "tea 0.0016324505375420496\n",
            "doesn't 0.0016751821406122169\n",
            "will 0.0016887563469787942\n",
            "price 0.0017118761490971638\n",
            "me 0.0017519621996635161\n",
            "time 0.0017830920233627744\n",
            "try 0.001796520321322419\n",
            "flavors 0.001797035194130733\n",
            "makes 0.0018068826293511757\n",
            "buy 0.0018231972944780905\n",
            "amazon 0.001885090470945283\n",
            "bag 0.001886735842652347\n",
            "also 0.001893788159538611\n",
            "do 0.0019123708161849226\n",
            "i 0.001942520420439648\n",
            "good 0.002003718517923197\n",
            "chips 0.0020991057440007165\n",
            "juice 0.0021104329794340883\n",
            "we 0.002146421573493279\n",
            "when 0.0021479139444232974\n",
            "because 0.0021511652990658494\n",
            "up 0.00236683805383219\n",
            "2 0.002445964638337537\n",
            "go 0.002470540206906046\n",
            "best 0.00251193312626057\n",
            "more 0.0025269058032092906\n",
            "should 0.0025312018882066994\n",
            "does 0.0025330470900521212\n",
            "my 0.0025428455712698645\n",
            "into 0.002545863753811696\n",
            "product 0.0026510819243734675\n",
            "other 0.0026758876748608357\n",
            "one 0.0029812029981947322\n",
            "don't 0.0030266578052493384\n",
            "great 0.0030515840237426194\n",
            "too 0.0031065718267120047\n",
            "no 0.0031271465489629527\n",
            "better 0.003136678918692627\n",
            "can 0.0031786248660089413\n",
            "coffee 0.0031986348792471153\n",
            "not 0.0037590452824486434\n",
            "about 0.003766079387725324\n",
            "? 0.003790862445725078\n",
            "be 0.0038033343372387307\n",
            "food 0.003921342436041769\n",
            "like 0.004214354561163483\n",
            "get 0.004233364272600807\n",
            "of 0.004300182724686472\n",
            "but 0.004315265125969455\n",
            "are 0.0043198449821470275\n",
            "taste 0.004751578439056126\n",
            "them 0.004752930283587428\n",
            "this 0.005035267370578958\n",
            "on 0.005215774728564931\n",
            "make 0.0052756544125895305\n",
            "it's 0.005816542361686353\n",
            "at 0.005847291665564219\n",
            "to 0.005861795927010241\n",
            "just 0.005976115744973638\n",
            "has 0.006034405789874374\n",
            "than 0.0064273023430082826\n",
            "have 0.0064312563276126685\n",
            "they 0.0065884255101609605\n",
            "! 0.00685669978992955\n",
            "out 0.007203155167740386\n",
            "or 0.007492901424207586\n",
            "with 0.012815591541989522\n",
            "was 0.013046547590860786\n",
            "from 0.013606519017546543\n",
            "for 0.016975618227085855\n",
            "as 0.01713109418770671\n",
            "a 0.019254238065974087\n",
            "is 0.02332435464576735\n",
            "in 0.027041042610307472\n",
            "and 0.02926841677954545\n",
            "br 0.030573045008163043\n",
            "the 0.05276752988673007\n",
            "<unk> 0.05718668602593321\n",
            ", 0.07101616579947234\n",
            ". 0.08211930050431016\n",
            "\n",
            "state 8\n",
            "mix 0.0013493478680412288\n",
            "popchips 0.0013664688688212908\n",
            "still 0.0013796705392518838\n",
            "first 0.0013809214925529826\n",
            "bag 0.001403254262396641\n",
            "believe 0.001412449236189824\n",
            "were 0.0014469696026281874\n",
            "or 0.001459105552918145\n",
            "try 0.0014889820378125363\n",
            "hard 0.0014897156856702694\n",
            "fan 0.0014903282211753638\n",
            "and 0.001524957022143289\n",
            "our 0.001604497988269\n",
            "an 0.001611895483328155\n",
            "bit 0.0016431791158811237\n",
            "different 0.0016518379536844489\n",
            "tastes 0.0016720374123831195\n",
            "your 0.0016920390004003677\n",
            "something 0.0016943755575137389\n",
            "you're 0.0016967936749947865\n",
            "did 0.001756664184409243\n",
            "disappointed 0.0018598293862966265\n",
            "decided 0.0019128495598380044\n",
            "wanted 0.0019638634197644976\n",
            "coffee 0.0019800693836977273\n",
            "kettle 0.002016599730178865\n",
            "get 0.0020419217429938703\n",
            "on 0.0020602303730376907\n",
            "going 0.002114969285783174\n",
            "be 0.0021641141250344415\n",
            "after 0.0022235583030387482\n",
            "find 0.0023016508340398282\n",
            "eat 0.00231302017528373\n",
            "it 0.002362255253347925\n",
            "www 0.002382384826841475\n",
            "think 0.0023941018861485526\n",
            "use 0.0025094804500887585\n",
            "ordered 0.0025616954310290984\n",
            "tried 0.0026352387502062984\n",
            "do 0.0027411853852517777\n",
            "used 0.0027784143360659796\n",
            "know 0.0028381146126543106\n",
            "don't 0.0028732017477643107\n",
            "thought 0.0030756815187347577\n",
            "taste 0.003112544774952217\n",
            "it's 0.003152098368951254\n",
            "so 0.0033182339736670874\n",
            "lot 0.003359494356205431\n",
            "chips 0.003414668597775525\n",
            "recommend 0.0035014518080182426\n",
            "up 0.0035219832740661663\n",
            "at 0.0035686321171532285\n",
            "just 0.003577284831968473\n",
            "what 0.0035920417834077495\n",
            "in 0.0037440104584885725\n",
            "better 0.003770918010391065\n",
            "product 0.003882085142035869\n",
            "! 0.004045320952135937\n",
            "bought 0.0040951463683494916\n",
            "for 0.004285837631205217\n",
            "little 0.004357981347076793\n",
            "as 0.004480734962777317\n",
            "i'm 0.004653831678579512\n",
            "when 0.004927228693295888\n",
            "them 0.004942846521682541\n",
            "had 0.0050410901440202036\n",
            "like 0.005045606065752615\n",
            "one 0.005097700856711326\n",
            "all 0.0052646534815438155\n",
            "with 0.005392873846392565\n",
            "can 0.005393522497132337\n",
            "of 0.005525352058204\n",
            "really 0.005592023149172586\n",
            "i've 0.006119300340819917\n",
            "br 0.006497563981880363\n",
            "will 0.0066950016949381\n",
            "very 0.007633432265974401\n",
            "we 0.00803706926472729\n",
            "not 0.008307018768722755\n",
            ". 0.008366310873064085\n",
            "the 0.008466365735212852\n",
            "am 0.009446212524487447\n",
            "that 0.009686865215599267\n",
            "would 0.009841891724237571\n",
            "to 0.009953921541006881\n",
            "love 0.010228606538459467\n",
            "my 0.01032560010462546\n",
            "good 0.011342354920900409\n",
            "a 0.012296757033845682\n",
            "great 0.01242484457418364\n",
            "if 0.012715169021345531\n",
            "have 0.013042997857226638\n",
            "is 0.014165221980781604\n",
            ", 0.014791517304544723\n",
            "was 0.015253139763313462\n",
            "these 0.020300007676551605\n",
            "you 0.021812265272310085\n",
            "this 0.037428344799905144\n",
            "<unk> 0.09689576298786481\n",
            "i 0.12534447011834973\n",
            "\n",
            "state 9\n",
            "stuff 0.0011066810254753612\n",
            "far 0.0011120795849813517\n",
            "didn't 0.0011480601041351935\n",
            "never 0.001162199921369777\n",
            "about 0.001169756926382889\n",
            "did 0.0011736919435710886\n",
            "coffee 0.0011863482055539376\n",
            "does 0.0011961013669700166\n",
            "though 0.001199867253718665\n",
            "; 0.0012122796806444507\n",
            "only 0.0012138471395696045\n",
            "well 0.0012353095770087034\n",
            "both 0.001254037750976023\n",
            "i'll 0.0012625608915389243\n",
            "don't 0.0012651746593459327\n",
            "now 0.001281002288212175\n",
            "mix 0.001347333976800145\n",
            "very 0.001360439551650373\n",
            "always 0.0013671634415838637\n",
            "juice 0.00138611207518239\n",
            "love 0.0014229242420997583\n",
            "c 0.0014286252570482989\n",
            "buy 0.001432088865256862\n",
            "thing 0.0014480543292723813\n",
            "came 0.001458878895724975\n",
            "use 0.0014712519857087482\n",
            "good 0.0014924210833951789\n",
            "flavor 0.0014985829512674089\n",
            "its 0.001509267795502358\n",
            "had 0.0015260332633240845\n",
            "two 0.001529053221125876\n",
            "amazon 0.0015652848080441454\n",
            "we 0.001607119801116926\n",
            "save 0.0016108509760948933\n",
            "your 0.0016561268153472736\n",
            "store 0.0016600241425180685\n",
            "find 0.0017240086258163458\n",
            "any 0.0017572255387082328\n",
            "however 0.0017579653670643217\n",
            "i've 0.0018213549153547287\n",
            "sweet 0.0019314097873324486\n",
            "great 0.0020527485222328356\n",
            "i'm 0.0020590045663291365\n",
            "because 0.0020713011219039793\n",
            "were 0.0021722127131289888\n",
            "vinegar 0.0021761628589169997\n",
            "other 0.0021806137255497076\n",
            "there 0.0022121371940122345\n",
            "it's 0.0022777053460991646\n",
            "can 0.0023072279785414113\n",
            "taste 0.00244080022536234\n",
            "at 0.002474053969322461\n",
            "as 0.0026157195584626024\n",
            "some 0.0026218379987717226\n",
            "even 0.0026437725322120873\n",
            "one 0.002732114154129358\n",
            "tastes 0.002741505650646652\n",
            "than 0.0027599567065258305\n",
            "been 0.0027935915915004157\n",
            "she 0.002823339432021379\n",
            "what 0.0028270869562409748\n",
            "was 0.0028413226617674337\n",
            "when 0.0029522435686447643\n",
            "tea 0.0030381665519453854\n",
            "after 0.0031696297806151886\n",
            "for 0.0032217814646165414\n",
            "just 0.003586151672700906\n",
            "! 0.003822340607963605\n",
            "like 0.004024794815515929\n",
            "all 0.004098457916859665\n",
            "you 0.004329307485476263\n",
            "has 0.004730853593740874\n",
            "no 0.004741665384624459\n",
            "br 0.0052662342672085615\n",
            "are 0.005875358285273016\n",
            "also 0.00589552840729178\n",
            "on 0.0066969984079891095\n",
            "much 0.006749942574735023\n",
            "if 0.0069148885056215395\n",
            "product 0.007383898083353225\n",
            "which 0.008350689304199398\n",
            "or 0.008442909417345884\n",
            "them 0.008565651249654086\n",
            "they 0.010203955385400303\n",
            "not 0.010584989036425336\n",
            "be 0.01157687154659435\n",
            "in 0.013398157145739198\n",
            "so 0.014059592777272626\n",
            "the 0.016125661322682065\n",
            "is 0.018742586899421543\n",
            "of 0.01902129575493239\n",
            "this 0.021785841433757114\n",
            "to 0.023763373233419746\n",
            "but 0.032347072959252925\n",
            "and 0.03539708538767169\n",
            "it 0.04370588324631822\n",
            "a 0.05279933355070012\n",
            "i 0.05948047309066834\n",
            "<unk> 0.06507506564899472\n",
            ". 0.0879204599666347\n",
            "\n",
            "log-likelihood -2078286.7325526422\n",
            "100 states:\n",
            "\n",
            "state 0\n",
            "have 0.00977966587531547\n",
            "but 0.011722897818487026\n",
            "are 0.012272375528028352\n",
            "not 0.012608579259201938\n",
            "it 0.013633068826429439\n",
            "of 0.014642662934781536\n",
            "br 0.015365477115106576\n",
            "to 0.015694436513742333\n",
            "is 0.017823453259430834\n",
            "a 0.020372611377990495\n",
            ". 0.023936295499690924\n",
            "and 0.037396170998063104\n",
            "the 0.04296721388822635\n",
            ", 0.06354214582558895\n",
            "<unk> 0.1145334929601823\n",
            "\n",
            "state 1\n",
            "is 0.008791206046134249\n",
            "but 0.010384235974853655\n",
            "these 0.010864066028906811\n",
            "in 0.011017227413798918\n",
            "it 0.01321883578883241\n",
            "for 0.014568789349961885\n",
            "and 0.02186992547778875\n",
            "my 0.023244505455218577\n",
            ", 0.029345329212797\n",
            "this 0.031966112784408064\n",
            "a 0.0323223839973221\n",
            "i 0.051580969056901495\n",
            ". 0.0534963484124717\n",
            "the 0.08654185648649568\n",
            "<unk> 0.1080686830306831\n",
            "\n",
            "state 2\n",
            ", 0.010242916850730456\n",
            "was 0.011315245061657613\n",
            "like 0.011326881892437388\n",
            "are 0.012699119515749958\n",
            "is 0.013034717496412133\n",
            "this 0.014042838418061063\n",
            "you 0.014098242713164446\n",
            "! 0.014479843039528826\n",
            "of 0.014544569323809793\n",
            "to 0.016665437387198685\n",
            "for 0.01836103202789627\n",
            "<unk> 0.037180602000109454\n",
            "a 0.03809430931664608\n",
            "the 0.05358325064827896\n",
            ". 0.06519448273627972\n",
            "\n",
            "state 3\n",
            "they 0.007877050737150119\n",
            "is 0.008096994454638613\n",
            "you 0.008486754880295934\n",
            "as 0.009551668185567797\n",
            "br 0.009794291533931423\n",
            "in 0.013028441745947283\n",
            "with 0.013850588342426898\n",
            "it 0.015036027967065884\n",
            "of 0.02475293080581427\n",
            "i 0.025600858130983187\n",
            "a 0.026493863448819856\n",
            "and 0.044709272342951696\n",
            ". 0.048865125221821494\n",
            ", 0.0581212427290145\n",
            "<unk> 0.1254974141903421\n",
            "\n",
            "state 4\n",
            "you 0.010785115036998442\n",
            "they 0.013307578555712693\n",
            ", 0.013855693026012866\n",
            "with 0.014585957100989196\n",
            "not 0.017793494532345824\n",
            "i 0.01833080557274857\n",
            "in 0.02047531270844371\n",
            "the 0.021500627378585817\n",
            "and 0.02535707347291672\n",
            "it 0.02600362571372169\n",
            "is 0.02664527922475249\n",
            "a 0.031530895811349706\n",
            "to 0.03273204789352339\n",
            "<unk> 0.0622260631375188\n",
            ". 0.06938959366664753\n",
            "\n",
            "state 5\n",
            "that 0.007956126948152726\n",
            "was 0.008781146108800517\n",
            "for 0.009860819146458961\n",
            "as 0.010154416308547746\n",
            "are 0.010808908809206685\n",
            "br 0.010815577166469886\n",
            "of 0.014909824861533607\n",
            "a 0.019850094205579323\n",
            "to 0.022023263431415557\n",
            "is 0.022761145935394096\n",
            "the 0.030952780647722392\n",
            "and 0.03878681142121723\n",
            ", 0.061623858005794487\n",
            "<unk> 0.09598253519371178\n",
            ". 0.10939862046643505\n",
            "\n",
            "state 6\n",
            "as 0.010830345938758333\n",
            "not 0.012328820956777935\n",
            "my 0.012767433710377765\n",
            "that 0.013027472801158757\n",
            "it 0.013435048537052316\n",
            "but 0.01434189061882194\n",
            "br 0.018792186820400507\n",
            ". 0.024488663206205675\n",
            "of 0.02459085844193014\n",
            ", 0.02678607189752463\n",
            "to 0.03219481029865905\n",
            "a 0.03918853721978599\n",
            "i 0.047348782927463334\n",
            "the 0.052887739278439316\n",
            "<unk> 0.06532005683754975\n",
            "\n",
            "state 7\n",
            "taste 0.008254014741971554\n",
            "product 0.008678654689638028\n",
            "and 0.009587006708242649\n",
            "are 0.009876165262977955\n",
            "you 0.012653269100458693\n",
            "is 0.014429152293316407\n",
            "! 0.01474398673655139\n",
            "that 0.015000430328582668\n",
            "in 0.018566749081365796\n",
            "the 0.019177803834128912\n",
            "for 0.022124059065135905\n",
            "<unk> 0.0403461691735717\n",
            ". 0.04993293502078482\n",
            "a 0.058835012628416145\n",
            ", 0.07946764351628474\n",
            "\n",
            "state 8\n",
            "have 0.009232125746593217\n",
            "br 0.010027023474596875\n",
            "is 0.010440170936289909\n",
            "i 0.010596430304323029\n",
            "they 0.011345790339791485\n",
            "not 0.014891021235797613\n",
            ", 0.017744701641182088\n",
            "in 0.01853145222639616\n",
            "to 0.021452115128112778\n",
            "this 0.022375227526306316\n",
            "of 0.026066015681002207\n",
            "and 0.02669044969786149\n",
            "it 0.03375135869153486\n",
            "<unk> 0.0505162314055949\n",
            ". 0.08816368014910138\n",
            "\n",
            "state 9\n",
            "this 0.01010511895175084\n",
            "with 0.011181283749219138\n",
            "have 0.013841794129510664\n",
            "in 0.014816124657089522\n",
            "for 0.016361660986980955\n",
            "that 0.01658182733605965\n",
            "of 0.01769858679468651\n",
            "it 0.018651983055708827\n",
            "and 0.02033592958023431\n",
            "is 0.021135024324594052\n",
            "the 0.026222534739165314\n",
            "a 0.030281132037790058\n",
            ", 0.033548610551993215\n",
            ". 0.056577799111740365\n",
            "<unk> 0.10583710851269951\n",
            "\n",
            "state 10\n",
            "of 0.010182687025039437\n",
            "i 0.01122421565313831\n",
            "not 0.01149962296425677\n",
            "this 0.012018956179539433\n",
            "have 0.012700302385793324\n",
            "as 0.012821934936177427\n",
            "it 0.015720946635229882\n",
            "in 0.016906625671903458\n",
            "are 0.017139328192630497\n",
            "but 0.01831699354879122\n",
            "the 0.02117477445345375\n",
            "for 0.02640610969357122\n",
            "is 0.03584255394376834\n",
            ", 0.04462121966302447\n",
            ". 0.06718172001468442\n",
            "\n",
            "state 11\n",
            "you 0.008727439762683326\n",
            "and 0.009090220406640809\n",
            "at 0.009228628409659902\n",
            "on 0.010571489982020666\n",
            "so 0.010621027589452794\n",
            "of 0.013396318144646377\n",
            "it 0.013399152237201959\n",
            "that 0.01428611182036344\n",
            "with 0.014852262917372258\n",
            "for 0.019558649430151533\n",
            ", 0.026861809842527225\n",
            "to 0.03483809654271726\n",
            "the 0.0654520860529233\n",
            ". 0.0847301795938505\n",
            "<unk> 0.10868968983795321\n",
            "\n",
            "state 12\n",
            "! 0.011710307716316384\n",
            "but 0.011797757808185136\n",
            "was 0.014409367419802728\n",
            "in 0.014481939718921184\n",
            "a 0.01546674909505596\n",
            "for 0.016523482998924637\n",
            "to 0.018827400328851704\n",
            "it 0.02096473968972398\n",
            "br 0.024701486420052484\n",
            "<unk> 0.02557732125237887\n",
            "of 0.027099280737830196\n",
            "this 0.03075809947551737\n",
            ", 0.03572686091998605\n",
            "and 0.03621290145133306\n",
            "the 0.06438925453690128\n",
            "\n",
            "state 13\n",
            "was 0.008151147385484584\n",
            "for 0.009313103413567362\n",
            "that 0.012580741063173043\n",
            "in 0.01397174213059784\n",
            "with 0.014187839270719012\n",
            "they 0.015202033157998033\n",
            "to 0.03285061375079755\n",
            ", 0.033770098992284996\n",
            "it 0.03476478057541974\n",
            "br 0.037385345282957366\n",
            "the 0.04044000684756343\n",
            ". 0.04278644588239431\n",
            "and 0.04567341873639287\n",
            "a 0.048700762045842054\n",
            "<unk> 0.07367409877575794\n",
            "\n",
            "state 14\n",
            "they 0.010319598893476918\n",
            "is 0.010555068030271602\n",
            "that 0.011325308696866467\n",
            "this 0.011472553388867124\n",
            "for 0.012035352553385233\n",
            "my 0.012621535292163017\n",
            "br 0.014449154872188072\n",
            "of 0.020094844874726705\n",
            "it 0.02471249163394354\n",
            "i 0.025771149819847013\n",
            "a 0.05046471519063936\n",
            ", 0.058969091553131715\n",
            "<unk> 0.06168002722776717\n",
            "the 0.07955610772968626\n",
            ". 0.07961603337266854\n",
            "\n",
            "state 15\n",
            "have 0.007432306470700263\n",
            "this 0.007883940362947806\n",
            "are 0.008506865738279105\n",
            "that 0.009222260831394298\n",
            "it 0.009500103740199039\n",
            "for 0.011391641627928287\n",
            "is 0.01523660301590395\n",
            "in 0.016502923854574518\n",
            "a 0.01831095422981988\n",
            "the 0.01968056760962715\n",
            "i 0.02821945564499903\n",
            "and 0.028718766190450554\n",
            ", 0.06657222570270291\n",
            ". 0.07821536230289128\n",
            "<unk> 0.13833171192222282\n",
            "\n",
            "state 16\n",
            "on 0.00952052653379288\n",
            "br 0.011211539071140416\n",
            "these 0.011440211169211168\n",
            "is 0.013375681687211902\n",
            "but 0.01771577963406441\n",
            "<unk> 0.022149481369466924\n",
            "my 0.022246359485700383\n",
            "to 0.023908050153328066\n",
            "and 0.024098561761304302\n",
            "of 0.02667620850282777\n",
            "the 0.03247764196375043\n",
            ", 0.03616803309721068\n",
            "a 0.04002785215040291\n",
            ". 0.08424988587433978\n",
            "i 0.08932588280231345\n",
            "\n",
            "state 17\n",
            "! 0.013319605580111195\n",
            "with 0.014523126818862982\n",
            "that 0.01454172054693626\n",
            "are 0.016651160220950895\n",
            "have 0.017450605991876273\n",
            "for 0.01777147459334649\n",
            "i 0.019131981511012284\n",
            "a 0.0203324139920197\n",
            "<unk> 0.020849967684193157\n",
            "br 0.0219191345358072\n",
            "it 0.023393317752431964\n",
            "to 0.024110700350275308\n",
            "and 0.024936563626721534\n",
            ", 0.04308294595882921\n",
            ". 0.052090530837199576\n",
            "\n",
            "state 18\n",
            "with 0.007812889002098632\n",
            "me 0.007889827860807736\n",
            "like 0.008240494460322979\n",
            "they 0.008548197421616959\n",
            "my 0.00926392794422779\n",
            "br 0.010411194796169726\n",
            ", 0.011588385212821135\n",
            "a 0.01718475944445293\n",
            "for 0.024189816547312015\n",
            "it 0.03509397269425757\n",
            "of 0.03653149877489493\n",
            "the 0.04157807736432728\n",
            ". 0.04522082108707311\n",
            "and 0.050697211177732814\n",
            "<unk> 0.13962772188832429\n",
            "\n",
            "state 19\n",
            "br 0.00959314078367728\n",
            "of 0.010501401236585352\n",
            "is 0.010730079520590624\n",
            "! 0.011195689447878035\n",
            "with 0.011580869528152656\n",
            "in 0.012072904715060622\n",
            "that 0.01222013928905112\n",
            "this 0.014044747721144793\n",
            "for 0.014508704216666666\n",
            "a 0.021679736204423025\n",
            "to 0.03260915225905534\n",
            "and 0.033440299751173984\n",
            ", 0.052137048469201926\n",
            ". 0.05629319028689965\n",
            "<unk> 0.13616603185592366\n",
            "\n",
            "state 20\n",
            "! 0.008521084171610922\n",
            "it 0.009474271282657393\n",
            "not 0.009505008854309802\n",
            "and 0.009848536647004469\n",
            "is 0.010312354716177105\n",
            "them 0.011395663953653183\n",
            "but 0.011411285651294593\n",
            "for 0.012278274571548122\n",
            "was 0.014526285478000292\n",
            "are 0.014790681446588886\n",
            "with 0.015773725619011872\n",
            ". 0.03434995916668289\n",
            "<unk> 0.03774530737683114\n",
            "a 0.04260148699871414\n",
            ", 0.06888567585688869\n",
            "\n",
            "state 21\n",
            "have 0.01058217198623818\n",
            "br 0.010862851107313562\n",
            "you 0.011114048971786175\n",
            "this 0.011856668852767854\n",
            "in 0.012086244597701733\n",
            "they 0.013475634036748462\n",
            "are 0.015069660130217152\n",
            "for 0.015490931502900752\n",
            ", 0.024711943821983516\n",
            "to 0.025855553292528352\n",
            "of 0.029868958418039087\n",
            "it 0.03587674073634819\n",
            "<unk> 0.03633084178251699\n",
            "the 0.05907504744722058\n",
            ". 0.09092333065158388\n",
            "\n",
            "state 22\n",
            "with 0.008221437202827205\n",
            "this 0.009305129046902182\n",
            "you 0.010176363606886929\n",
            "br 0.011187190082908166\n",
            "i 0.011463086397332466\n",
            "not 0.011569179733349422\n",
            "have 0.011713013146446703\n",
            "and 0.012020986322923484\n",
            "that 0.013603026530247267\n",
            "in 0.013616863731552483\n",
            "to 0.03490070240028007\n",
            "a 0.038786045178708026\n",
            "the 0.05337207259746789\n",
            "<unk> 0.06816341808037517\n",
            ". 0.07486572638796171\n",
            "\n",
            "state 23\n",
            "for 0.00956248051232993\n",
            "this 0.010307986322644486\n",
            "with 0.011197361072755612\n",
            "that 0.011233275091324546\n",
            "not 0.011282819288737094\n",
            "a 0.012166188425053496\n",
            "br 0.012263090218678954\n",
            "is 0.013275920009992436\n",
            "it 0.015747782403806584\n",
            "of 0.029609045195386038\n",
            "the 0.033236212757242325\n",
            ", 0.035859577696443615\n",
            "and 0.045699231006928756\n",
            ". 0.08219875128327957\n",
            "<unk> 0.12855083755268254\n",
            "\n",
            "state 24\n",
            "in 0.010501826613450617\n",
            "they 0.01062003551764688\n",
            "that 0.011163377905917404\n",
            "but 0.012351555751622086\n",
            "was 0.01318827384798246\n",
            "! 0.013737725423474774\n",
            "<unk> 0.018391042873303686\n",
            "of 0.01844166101036745\n",
            "and 0.02134483841605902\n",
            "br 0.025020305494251525\n",
            "it 0.03058679796465325\n",
            ", 0.03091985288298962\n",
            "to 0.03164753706002523\n",
            "i 0.041377715486465995\n",
            ". 0.086761906951651\n",
            "\n",
            "state 25\n",
            "was 0.008322430449270045\n",
            "this 0.009403703548011722\n",
            "and 0.010292134551970354\n",
            "not 0.011119218977188042\n",
            "for 0.013747096893028157\n",
            "in 0.014775955547078888\n",
            "a 0.015078661149969062\n",
            "br 0.01601294453035266\n",
            "to 0.018513145155718357\n",
            "is 0.02319587846536618\n",
            "of 0.023406504311787254\n",
            "it 0.025964039606839448\n",
            "the 0.049262339246552565\n",
            ", 0.06147876157136995\n",
            "<unk> 0.16743320279496662\n",
            "\n",
            "state 26\n",
            "you 0.009691440596940201\n",
            "that 0.010026160620198234\n",
            "! 0.0127173238155881\n",
            "was 0.015462132013746126\n",
            "a 0.015665235885548783\n",
            "it 0.01708391687371637\n",
            "to 0.01734377278755106\n",
            "the 0.01830258264456712\n",
            "br 0.01982266971627893\n",
            "is 0.0201940935398146\n",
            "of 0.028654263503882046\n",
            ", 0.033458623084896104\n",
            "and 0.04448707784813101\n",
            ". 0.08586776939557987\n",
            "<unk> 0.1047466120297599\n",
            "\n",
            "state 27\n",
            "taste 0.006841825259012142\n",
            "flavor 0.006884196665438656\n",
            "in 0.007810075670470973\n",
            "them 0.009335013356106443\n",
            "but 0.009884751221446159\n",
            "and 0.010477380979755537\n",
            "with 0.015668671285605087\n",
            "for 0.019212709856290824\n",
            "of 0.02621677773901652\n",
            "it 0.027844010374319886\n",
            ", 0.028554441596032706\n",
            ". 0.03140795075584469\n",
            "a 0.038645894705001085\n",
            "to 0.045563312351093566\n",
            "<unk> 0.07367879818885624\n",
            "\n",
            "state 28\n",
            "it 0.009320550401494454\n",
            "this 0.009935163885391578\n",
            "not 0.01149895340039443\n",
            "br 0.012965846816710874\n",
            "was 0.013295612922069421\n",
            "for 0.014582663068949894\n",
            "in 0.01549280647874083\n",
            "is 0.02228204427084393\n",
            ", 0.022385739271355693\n",
            "to 0.02347364046174653\n",
            "of 0.02627628845480788\n",
            "a 0.03843950276691305\n",
            "the 0.042227023480694736\n",
            ". 0.11665839519395584\n",
            "<unk> 0.11692791162902931\n",
            "\n",
            "state 29\n",
            "them 0.008117385584174712\n",
            "taste 0.008313388322973393\n",
            "are 0.00959022393088344\n",
            "that 0.012141446180516626\n",
            "for 0.012270588505632072\n",
            "a 0.012676628823519852\n",
            "in 0.01288174626507741\n",
            "of 0.0169609986095068\n",
            "br 0.020454940910587013\n",
            "it 0.027116400600228234\n",
            ", 0.0294015297159046\n",
            "and 0.033969901075797795\n",
            "<unk> 0.05929959754530748\n",
            "the 0.05930665745406393\n",
            ". 0.10667040723274177\n",
            "\n",
            "state 30\n",
            "that 0.013450155240842034\n",
            "for 0.013744029407095501\n",
            "you 0.013975020242641342\n",
            "this 0.014226675498644441\n",
            "they 0.014437348958145288\n",
            "to 0.01576506252675315\n",
            "my 0.01578087426008296\n",
            "in 0.017527046177813043\n",
            "br 0.019856966714465043\n",
            "is 0.020010175922337496\n",
            "it 0.028772075403048103\n",
            "<unk> 0.04411667967935131\n",
            "a 0.046357093736495734\n",
            "i 0.05097707789379967\n",
            ". 0.08246217663776496\n",
            "\n",
            "state 31\n",
            "are 0.00788986187751771\n",
            "in 0.00817384159725484\n",
            "as 0.008656832537426178\n",
            "so 0.009656252463986615\n",
            "with 0.010331569579032945\n",
            "but 0.012569393998574601\n",
            "this 0.012763206163103096\n",
            "to 0.015157364345860522\n",
            "is 0.0192870807930544\n",
            ", 0.02691079329879952\n",
            "the 0.03328684809493261\n",
            "a 0.03838361882181848\n",
            "and 0.05140685059468848\n",
            "<unk> 0.09894149455244762\n",
            ". 0.1036523551368576\n",
            "\n",
            "state 32\n",
            "was 0.008971101743799339\n",
            "as 0.009788504163150578\n",
            "! 0.013481978189449389\n",
            "but 0.013563438550789052\n",
            "in 0.014178413570188902\n",
            "and 0.0164557607121149\n",
            "of 0.018018880232599135\n",
            "it 0.02035021386207646\n",
            "i 0.021783539427180636\n",
            "a 0.024762610759145716\n",
            "to 0.025808952228772546\n",
            "br 0.03143091732661469\n",
            "the 0.07696006324793887\n",
            ". 0.08880400273382584\n",
            "<unk> 0.11021698061509513\n",
            "\n",
            "state 33\n",
            "i 0.010463032836457536\n",
            "of 0.010797518760496469\n",
            "was 0.011057070022678955\n",
            "and 0.011621589191906829\n",
            "this 0.012872232471111408\n",
            ", 0.01287773850432352\n",
            "! 0.013761679340715456\n",
            "but 0.013794057468196286\n",
            "for 0.01722249827478419\n",
            "is 0.021339146592098814\n",
            "it 0.021815012888033003\n",
            "to 0.02543173979079886\n",
            ". 0.03530672117853888\n",
            "a 0.040979164427497876\n",
            "<unk> 0.08011547825539912\n",
            "\n",
            "state 34\n",
            "they 0.01012908119823178\n",
            "for 0.010916438375567251\n",
            "with 0.011062264203628271\n",
            "you 0.011766488749854667\n",
            "that 0.013000975867584686\n",
            "to 0.0130645541515211\n",
            "i 0.013854535610552539\n",
            "br 0.014805401482300128\n",
            "in 0.016674341777878864\n",
            ". 0.019072350672274124\n",
            "is 0.02017103584221223\n",
            "and 0.027751472217505006\n",
            "it 0.031106989955790823\n",
            ", 0.031881565495279166\n",
            "<unk> 0.16201702838080234\n",
            "\n",
            "state 35\n",
            "this 0.011664377300189353\n",
            "in 0.011768520903577417\n",
            "! 0.012843084635875553\n",
            "not 0.015488736098736985\n",
            "that 0.015770019850530753\n",
            "are 0.01583772974264617\n",
            "br 0.016349246934412802\n",
            "have 0.020714421580493494\n",
            ", 0.025894296689180838\n",
            "the 0.026122846799355413\n",
            "a 0.0285151099476186\n",
            "of 0.031087975549777255\n",
            "to 0.032912218130925486\n",
            "and 0.03464655948858001\n",
            "<unk> 0.07118412943212991\n",
            "\n",
            "state 36\n",
            "are 0.012661240005939956\n",
            "! 0.013237038118144478\n",
            "was 0.014132137291593313\n",
            "for 0.014693942194198195\n",
            "that 0.014761955837183122\n",
            "in 0.017328185959470773\n",
            "of 0.018724932047000153\n",
            "<unk> 0.02046149345539243\n",
            "it 0.024602061119915367\n",
            "and 0.02870466054788366\n",
            "is 0.030063091493937124\n",
            ". 0.03037760196041106\n",
            "a 0.035797157342001784\n",
            "the 0.0469351951756853\n",
            ", 0.05558625930218057\n",
            "\n",
            "state 37\n",
            "so 0.008796806330871708\n",
            "but 0.008837210930835594\n",
            "! 0.009367752369741985\n",
            "was 0.009713750641281544\n",
            "this 0.011915756637436234\n",
            "of 0.013780284337493561\n",
            "with 0.015214975222945813\n",
            "you 0.016093968967897426\n",
            "not 0.01700037646711583\n",
            ". 0.017397435941035114\n",
            ", 0.025054533387950252\n",
            "it 0.03147948312304397\n",
            "and 0.03378867079111537\n",
            "the 0.046460740200615865\n",
            "<unk> 0.13588006895613047\n",
            "\n",
            "state 38\n",
            "not 0.008638083414310818\n",
            "so 0.008938834110442854\n",
            "br 0.00903114506026804\n",
            "! 0.009859827892818362\n",
            "are 0.011007800624900838\n",
            "but 0.013333042475909307\n",
            "that 0.013849413426434922\n",
            "for 0.020967438242668023\n",
            "to 0.02164460589276804\n",
            "of 0.02733832567287217\n",
            "and 0.03479171073204551\n",
            "a 0.04369874658131788\n",
            ", 0.07038158110313725\n",
            "<unk> 0.08093127483651522\n",
            ". 0.11340227566511128\n",
            "\n",
            "state 39\n",
            "my 0.010270178609187925\n",
            "so 0.010618610030742149\n",
            "of 0.011202323944911032\n",
            "for 0.011253802244679884\n",
            "but 0.011496794192981918\n",
            "! 0.015857795571848708\n",
            "to 0.016405938216079614\n",
            "this 0.01794033881464573\n",
            "it 0.020133491691168116\n",
            "the 0.02048901731848204\n",
            "i 0.029475089569754673\n",
            "br 0.032546038400668796\n",
            ", 0.034790818336510966\n",
            "<unk> 0.05946923402253531\n",
            ". 0.16826888115339192\n",
            "\n",
            "state 40\n",
            "but 0.010519992218018671\n",
            "you 0.011011541113402397\n",
            "that 0.011941930861081269\n",
            "have 0.015021640737295987\n",
            "i 0.015309146912401372\n",
            "the 0.015495883258288207\n",
            "br 0.016827725934656965\n",
            "this 0.019414089377915743\n",
            "a 0.02090821689979673\n",
            "of 0.02538600101005673\n",
            "and 0.02575969365088113\n",
            ", 0.02594034909748403\n",
            "it 0.03443956976211277\n",
            "<unk> 0.05493526935901783\n",
            ". 0.11405013430539405\n",
            "\n",
            "state 41\n",
            "in 0.009752447424372583\n",
            "as 0.010239644320135478\n",
            "is 0.010624086300723484\n",
            "these 0.011791202694435817\n",
            "they 0.012937066123565204\n",
            "my 0.014462803861041073\n",
            "a 0.017496123384203175\n",
            "it 0.018834364432610797\n",
            ". 0.02177032228153244\n",
            "of 0.025110373412770004\n",
            "this 0.02807221528312528\n",
            "the 0.05263614791303383\n",
            ", 0.055297188642782394\n",
            "i 0.06708795650735801\n",
            "<unk> 0.12488531988314089\n",
            "\n",
            "state 42\n",
            "in 0.01190206720066467\n",
            "to 0.012427674355452653\n",
            "! 0.013505550009752048\n",
            "as 0.014274378290881993\n",
            "not 0.016071150481802403\n",
            "that 0.016563380557529723\n",
            "is 0.020345346210080974\n",
            "but 0.02074474881045221\n",
            "i 0.02523027818994772\n",
            "it 0.025729423190288557\n",
            "br 0.027637327512181276\n",
            "the 0.036098689468309735\n",
            "and 0.03702604182490474\n",
            ", 0.06020416518942458\n",
            "<unk> 0.09151662897570931\n",
            "\n",
            "state 43\n",
            "you 0.008162037141273748\n",
            "! 0.010249281841571103\n",
            "they 0.010524385008266643\n",
            "that 0.01163735565326148\n",
            "br 0.011831319129084352\n",
            "in 0.01505287193486385\n",
            "to 0.016105205042899542\n",
            ", 0.01863104458359576\n",
            "<unk> 0.023203700573109165\n",
            "i 0.02776851910716704\n",
            "is 0.02981273641235051\n",
            "of 0.03087472592541672\n",
            "a 0.035217818666508346\n",
            "the 0.07571083433690767\n",
            ". 0.11220410054449449\n",
            "\n",
            "state 44\n",
            "not 0.014005902224112642\n",
            "i 0.014087631679631321\n",
            "they 0.014362740746732569\n",
            "you 0.015910664028378672\n",
            "of 0.016387307005631943\n",
            "it 0.017630640971147412\n",
            "br 0.018222499083525835\n",
            "for 0.019764676124012632\n",
            "is 0.025891369385946474\n",
            ". 0.028131671482600505\n",
            "to 0.03548026466871604\n",
            "<unk> 0.041263578109527556\n",
            "and 0.04750489704900117\n",
            "a 0.050942176199835494\n",
            "the 0.07547960139060118\n",
            "\n",
            "state 45\n",
            "with 0.007219016703006874\n",
            "like 0.007683620253665473\n",
            "my 0.009071631286510453\n",
            "! 0.00989858748906851\n",
            "that 0.010531758481043844\n",
            "a 0.011347464017171516\n",
            "it 0.011775311331628721\n",
            "for 0.01651723970916076\n",
            "in 0.019246993645335338\n",
            "to 0.025745461250230778\n",
            "of 0.03470554478214776\n",
            "and 0.03565358255631974\n",
            "the 0.04819040884577956\n",
            ". 0.07402412202511822\n",
            "<unk> 0.10758603046763601\n",
            "\n",
            "state 46\n",
            "not 0.00850531636695369\n",
            ", 0.009279943686074809\n",
            "are 0.009424194679516596\n",
            "the 0.010013821179074232\n",
            "this 0.010112987497093192\n",
            "and 0.011021689855630618\n",
            "that 0.0133894609262285\n",
            "! 0.013436819178712221\n",
            "have 0.01464789762428853\n",
            "to 0.021839630074817894\n",
            "a 0.024002290195454124\n",
            "of 0.025988066914699792\n",
            "br 0.02928801867373168\n",
            ". 0.03408203771875693\n",
            "<unk> 0.07872136887676938\n",
            "\n",
            "state 47\n",
            "that 0.011002614845891434\n",
            "was 0.011024836590334739\n",
            "are 0.011369846751632443\n",
            "<unk> 0.01210677814854502\n",
            "for 0.013110423553924173\n",
            "and 0.016513529748721077\n",
            "of 0.018456907806704635\n",
            "it 0.019832614198299126\n",
            "the 0.02469498324315907\n",
            "i 0.027646313633900778\n",
            "a 0.031665136524855475\n",
            "to 0.03473430932858979\n",
            "br 0.0406113215151736\n",
            ", 0.041339071239630716\n",
            ". 0.11474686614813627\n",
            "\n",
            "state 48\n",
            "on 0.008799382816628938\n",
            "product 0.00903841066460809\n",
            "was 0.00939851391421579\n",
            "in 0.010201160296613835\n",
            "that 0.010615888852549323\n",
            "for 0.011098023951423234\n",
            "br 0.011837910184505333\n",
            "you 0.012082116904598844\n",
            "and 0.013354635587976388\n",
            "is 0.018989662981056216\n",
            "of 0.025081925632272656\n",
            "a 0.03926551913874339\n",
            ". 0.053167307018002034\n",
            "the 0.057000381325461556\n",
            "<unk> 0.15535139939981688\n",
            "\n",
            "state 49\n",
            "of 0.009489869422866027\n",
            "have 0.009532765117305216\n",
            "that 0.009712035824950453\n",
            "are 0.009795944875452248\n",
            "in 0.010058753871318467\n",
            "my 0.010877978114779873\n",
            "it 0.011362209026417148\n",
            "and 0.014052310664453472\n",
            "is 0.01924880785400916\n",
            "br 0.019441637875081245\n",
            "a 0.04179273873309505\n",
            ", 0.0519304575813256\n",
            "i 0.05620061610466337\n",
            "the 0.061370207677698026\n",
            "<unk> 0.07120039977120794\n",
            "\n",
            "state 50\n",
            "they 0.008268459654062744\n",
            "for 0.008753001582836572\n",
            "in 0.010504623767215912\n",
            "the 0.010783590574740274\n",
            "with 0.011776920886428252\n",
            "of 0.012025977846864525\n",
            "that 0.01463232428818635\n",
            "but 0.016446081812639932\n",
            "this 0.01794981333768498\n",
            "br 0.02042192501690116\n",
            "i 0.022679269620609368\n",
            "to 0.031244588725795785\n",
            "and 0.042405455542075594\n",
            "<unk> 0.08912672860990442\n",
            ". 0.14683911875903902\n",
            "\n",
            "state 51\n",
            "with 0.009850283982930847\n",
            "that 0.010400792482673936\n",
            "a 0.010420533926096202\n",
            "my 0.01252166275602643\n",
            ". 0.013784936573927138\n",
            "but 0.014423965756733253\n",
            "and 0.01590633656869715\n",
            "it 0.016303346912985357\n",
            "the 0.01980027819341612\n",
            "br 0.022758175604702276\n",
            "is 0.022895642294163274\n",
            "i 0.02914297981726819\n",
            "to 0.035272727292395493\n",
            ", 0.06530938566517916\n",
            "<unk> 0.13149560178620123\n",
            "\n",
            "state 52\n",
            "to 0.009855791143358836\n",
            "! 0.010437005530781926\n",
            "but 0.010702414672202216\n",
            "a 0.011929077394059396\n",
            "as 0.012631142791049682\n",
            "i'm 0.014108422223600077\n",
            "we 0.014327272761907341\n",
            "if 0.015487752939923029\n",
            "these 0.01973599835938092\n",
            "this 0.020536055623811205\n",
            "and 0.022218732563685756\n",
            ", 0.04280154310264787\n",
            "<unk> 0.04352737781532787\n",
            ". 0.06678441076645372\n",
            "i 0.17869107290708744\n",
            "\n",
            "state 53\n",
            "in 0.009507988014800808\n",
            "with 0.010579795802939594\n",
            "! 0.013576157910464877\n",
            "for 0.0170115517941133\n",
            "of 0.01800980254015236\n",
            "i 0.01858702323936634\n",
            "is 0.02207562394723606\n",
            "a 0.02278417841443407\n",
            ", 0.023435226584722968\n",
            "and 0.02470574503148315\n",
            "to 0.02760882955713372\n",
            "the 0.03693291133968766\n",
            "br 0.04331936768593826\n",
            "<unk> 0.04890628132324241\n",
            ". 0.14097021270233623\n",
            "\n",
            "state 54\n",
            "i'm 0.00817260799692626\n",
            "with 0.010026148813648508\n",
            "of 0.012358280348338918\n",
            "br 0.014722294193988968\n",
            "to 0.015421608772566564\n",
            "my 0.01674204166793132\n",
            ", 0.016830540881590396\n",
            "and 0.017780306177303303\n",
            "a 0.02022998709347146\n",
            ". 0.025570411485787616\n",
            "<unk> 0.029326906633720225\n",
            "it 0.03941270765663825\n",
            "this 0.058398922026736806\n",
            "the 0.11159907274776527\n",
            "i 0.11232058180544559\n",
            "\n",
            "state 55\n",
            "if 0.010703419679187576\n",
            "was 0.010806611315852418\n",
            "you 0.012065162027265881\n",
            "<unk> 0.012398835089854416\n",
            "of 0.016478659954540738\n",
            "my 0.01791709044091566\n",
            "in 0.018122271094314017\n",
            "and 0.01925766002465464\n",
            "to 0.02321698092845494\n",
            "it 0.02629349618748331\n",
            "this 0.034562850467868146\n",
            ", 0.035283384108648376\n",
            "the 0.037652084443871414\n",
            ". 0.04037471855419355\n",
            "i 0.06513089985439488\n",
            "\n",
            "state 56\n",
            "! 0.010504876031425513\n",
            "not 0.01148158293539298\n",
            "with 0.011498222803755355\n",
            "a 0.013249640752897255\n",
            "for 0.014646332019581283\n",
            "in 0.01508193058852045\n",
            "is 0.01608280160541834\n",
            "br 0.016263206979273626\n",
            "to 0.017934365230182183\n",
            "i 0.01926748868704918\n",
            "of 0.026997684018111204\n",
            ". 0.03221486777603693\n",
            "and 0.03877854990797709\n",
            ", 0.059559469675169376\n",
            "<unk> 0.11480888837561053\n",
            "\n",
            "state 57\n",
            ", 0.011509660698078702\n",
            "is 0.013018546583274011\n",
            "a 0.013285588529477572\n",
            "br 0.01329303179729371\n",
            "to 0.015920236615599995\n",
            "if 0.01647485299040944\n",
            "and 0.018049960769059795\n",
            "this 0.02110424166675439\n",
            ". 0.02441295247185083\n",
            "we 0.02532705128119039\n",
            "the 0.03385853967508217\n",
            "<unk> 0.03631220935395192\n",
            "my 0.03849864346229803\n",
            "these 0.04500635735083159\n",
            "i 0.22915566101790347\n",
            "\n",
            "state 58\n",
            "br 0.010680947535656833\n",
            "that 0.01253277794377789\n",
            "and 0.012598659341452606\n",
            ". 0.013279763662833882\n",
            "but 0.015871798786090543\n",
            "in 0.016233528813950807\n",
            "of 0.017401449969038335\n",
            "not 0.018130889762620974\n",
            "my 0.01935390243475055\n",
            "a 0.02059984802275382\n",
            "to 0.021829581190087394\n",
            "the 0.034315662505090584\n",
            "<unk> 0.05381196349209884\n",
            "this 0.05487477658885153\n",
            "i 0.07929992455813276\n",
            "\n",
            "state 59\n",
            "have 0.009811217052776959\n",
            "was 0.01099443660530607\n",
            "in 0.0117388886617295\n",
            "you 0.011741869253899589\n",
            "this 0.012636017096451499\n",
            "but 0.013015316201004719\n",
            "! 0.014510878162078886\n",
            "to 0.016088750797041928\n",
            "<unk> 0.02187053943166854\n",
            ". 0.024724090839154382\n",
            "is 0.027584914535624096\n",
            "a 0.03370318416365748\n",
            "and 0.03863868360431709\n",
            ", 0.05640663387777123\n",
            "the 0.0566997183799345\n",
            "\n",
            "state 60\n",
            "with 0.010440169773461098\n",
            "they 0.010485324021036519\n",
            "this 0.010969342947044627\n",
            "is 0.011757498950479148\n",
            ", 0.011817818848134366\n",
            "not 0.012702008855367403\n",
            "to 0.014342347293385868\n",
            "i 0.019554415359490266\n",
            "br 0.01973147830734547\n",
            "of 0.02392036806189144\n",
            "<unk> 0.02804398831630754\n",
            "it 0.0331657699179953\n",
            "and 0.03882546793019724\n",
            "the 0.06678600710772904\n",
            ". 0.11102791940197708\n",
            "\n",
            "state 61\n",
            "with 0.008738136961039972\n",
            "in 0.009171002050207246\n",
            "they 0.009723061387887037\n",
            "like 0.009898032793748873\n",
            "was 0.011472611056134872\n",
            "but 0.011670129120246769\n",
            "my 0.011680783373967309\n",
            "for 0.0117353026970519\n",
            "not 0.01634282633189195\n",
            "it 0.022396805370124333\n",
            "of 0.02537196812189282\n",
            ", 0.03510494004215747\n",
            "to 0.04480498889023626\n",
            "<unk> 0.0750161250192352\n",
            ". 0.10071829152851683\n",
            "\n",
            "state 62\n",
            "would 0.009368662500241943\n",
            "they 0.00954868718970835\n",
            "to 0.010174059801389584\n",
            "but 0.01052038967915528\n",
            "i 0.010695783458246294\n",
            ". 0.012563798098216268\n",
            "not 0.014675753942065632\n",
            "are 0.01594502614514029\n",
            "am 0.0159746423673908\n",
            "of 0.01872994334098195\n",
            "have 0.02369475260094207\n",
            "was 0.025100167534572306\n",
            "it 0.03310834188687905\n",
            "br 0.03774727190572276\n",
            "a 0.048530317111613944\n",
            "\n",
            "state 63\n",
            "the 0.009872344440155017\n",
            "for 0.010883504516210774\n",
            "are 0.011006803383073877\n",
            "so 0.011309166514769771\n",
            "to 0.011356395823640203\n",
            "as 0.011402952425285915\n",
            "but 0.015113256390808431\n",
            "is 0.015433627806536619\n",
            "in 0.020313058307971314\n",
            "i 0.02188921929791582\n",
            "and 0.02487080863629632\n",
            "it 0.028173806707650663\n",
            ", 0.054381327963501994\n",
            "<unk> 0.08959917420310852\n",
            ". 0.17087748359006663\n",
            "\n",
            "state 64\n",
            "my 0.009749642517167157\n",
            "is 0.011243593082144086\n",
            "a 0.011794646536679491\n",
            "have 0.012287555530536415\n",
            "for 0.01235598769476637\n",
            "are 0.013085974741483474\n",
            "was 0.014106032505224252\n",
            "not 0.01529274821077998\n",
            ". 0.01711646925412049\n",
            "to 0.020366840910230277\n",
            "the 0.021502296606615432\n",
            "it 0.03880312046491184\n",
            "i 0.04362593198854595\n",
            "br 0.04510405769126028\n",
            "<unk> 0.06818653425715666\n",
            "\n",
            "state 65\n",
            "are 0.008620399328575919\n",
            "be 0.008973162795465103\n",
            "br 0.009015804638930938\n",
            "in 0.010552893173197728\n",
            "it 0.010986259896386222\n",
            "of 0.012230284767127817\n",
            "but 0.013133269894528048\n",
            "i 0.01618098666545162\n",
            ". 0.01624498852348746\n",
            "is 0.01820824589575354\n",
            "for 0.019673721338145964\n",
            "the 0.028906490135050183\n",
            "and 0.043762069525175785\n",
            ", 0.061320839969968684\n",
            "<unk> 0.1341107930353612\n",
            "\n",
            "state 66\n",
            "not 0.008147169443674206\n",
            "my 0.008246035398225588\n",
            "! 0.008305046913567668\n",
            "that 0.008503905017784008\n",
            "like 0.008906165653525304\n",
            "the 0.009328738935853658\n",
            "but 0.012147617498010936\n",
            "of 0.019035569881367627\n",
            "in 0.0190358958424808\n",
            "for 0.02279394923060047\n",
            "to 0.023371708980927726\n",
            "and 0.02742410380015826\n",
            ", 0.04986472935379924\n",
            ". 0.05058203183680723\n",
            "<unk> 0.08287562120909744\n",
            "\n",
            "state 67\n",
            "to 0.009582248269241408\n",
            "have 0.010613333308437082\n",
            "and 0.011728198853768572\n",
            "if 0.011757546394162757\n",
            "was 0.01393638233857442\n",
            "br 0.016158364512833475\n",
            "this 0.0173522911534812\n",
            "of 0.018633408063090634\n",
            "my 0.023180388723831897\n",
            "a 0.023665191198231798\n",
            "these 0.029486955096714344\n",
            ", 0.03908086099510228\n",
            "<unk> 0.04252508894093943\n",
            ". 0.06753785484487054\n",
            "i 0.15220220707183002\n",
            "\n",
            "state 68\n",
            "as 0.006989342485900179\n",
            "like 0.007023541458129718\n",
            "them 0.007179309291098966\n",
            "so 0.0071806241486070815\n",
            "a 0.01015326796797216\n",
            "are 0.012695900679120608\n",
            "that 0.013524812719630153\n",
            "and 0.015780288760135902\n",
            "for 0.018055719236691446\n",
            "i 0.01924369874676992\n",
            "br 0.02118011255565195\n",
            "to 0.034157205732572055\n",
            "the 0.05987430380476017\n",
            ". 0.06494410719052769\n",
            "<unk> 0.1698157039569822\n",
            "\n",
            "state 69\n",
            "was 0.009862011839944474\n",
            "but 0.009874101843375508\n",
            "you 0.011838737099643355\n",
            "this 0.01193963201638158\n",
            "with 0.012740184432370788\n",
            "! 0.013514711863884081\n",
            "i 0.01469149207295216\n",
            "for 0.020509120590000547\n",
            "it 0.023854709122986435\n",
            "is 0.034905138370057265\n",
            "<unk> 0.037255693724886164\n",
            "to 0.03998455946047699\n",
            "and 0.05174815494980106\n",
            "the 0.06501433568628344\n",
            ", 0.07123677645801062\n",
            "\n",
            "state 70\n",
            "these 0.00850324103977709\n",
            "was 0.00997035305081021\n",
            "that 0.011321355920008408\n",
            "you 0.012037386783234138\n",
            "in 0.013964724405236544\n",
            "is 0.014330900571308711\n",
            "it 0.014367773370671242\n",
            "br 0.016079032352616155\n",
            "i 0.01720005505750919\n",
            ", 0.017808416982413346\n",
            "to 0.02077169940810575\n",
            "this 0.022185955876154313\n",
            "of 0.024541953872642158\n",
            "the 0.07279022838655065\n",
            "<unk> 0.12532965255860998\n",
            "\n",
            "state 71\n",
            "was 0.009996163121300911\n",
            "! 0.010059971952435902\n",
            "in 0.010165987142747414\n",
            "have 0.010380722535847237\n",
            "on 0.010423919274063479\n",
            "for 0.011446573206013921\n",
            "as 0.011586504673485988\n",
            "that 0.01194683292163978\n",
            "this 0.012077128818091866\n",
            "with 0.014139723487323421\n",
            "is 0.016461874077215027\n",
            "of 0.017317156432810937\n",
            "the 0.05941624531991259\n",
            "<unk> 0.10113638809186878\n",
            ". 0.1507406392849405\n",
            "\n",
            "state 72\n",
            "that 0.00864366819754424\n",
            "them 0.008680846197855975\n",
            "this 0.008705928848815832\n",
            "as 0.008775894400593662\n",
            "it 0.010154764563501676\n",
            "to 0.012700096158486666\n",
            "my 0.014618768387129161\n",
            "of 0.017810566883417638\n",
            "a 0.01784519991249804\n",
            "and 0.017923442637044176\n",
            "i 0.027954543237672706\n",
            ". 0.04053367026826696\n",
            ", 0.0685908679605266\n",
            "the 0.08216328435678795\n",
            "<unk> 0.11518367390874301\n",
            "\n",
            "state 73\n",
            "they 0.011537886144978651\n",
            "a 0.011747805220931705\n",
            "for 0.01223283425231131\n",
            "in 0.01360963355657788\n",
            "but 0.013752237252784141\n",
            "! 0.016697659761085046\n",
            "to 0.021741177402795065\n",
            "br 0.022233773403930363\n",
            "i 0.0238859408788008\n",
            "the 0.024691232392082933\n",
            "it 0.029505237472582303\n",
            "<unk> 0.0328494803136826\n",
            ". 0.04134409883468749\n",
            "and 0.04426187463342821\n",
            ", 0.08509495210112526\n",
            "\n",
            "state 74\n",
            "my 0.011515995700339355\n",
            "with 0.012508524207463748\n",
            "you 0.01296100172919333\n",
            "is 0.013001465474202304\n",
            "they 0.013124727239864104\n",
            "br 0.013650680668343306\n",
            "was 0.015136343078024198\n",
            "<unk> 0.017952333361752098\n",
            "in 0.0183695265699001\n",
            "to 0.019250606126022772\n",
            "a 0.020703936727671363\n",
            ", 0.027529008925791618\n",
            "i 0.028708119433214767\n",
            "it 0.04082871303792517\n",
            "the 0.10505225787415864\n",
            "\n",
            "state 75\n",
            "good 0.006449973928653979\n",
            "them 0.007086984573858368\n",
            "as 0.007741393375330454\n",
            "are 0.009402633200703328\n",
            "br 0.010613652439808424\n",
            "in 0.011311512936778206\n",
            "that 0.012545974849445902\n",
            "is 0.01726233075591911\n",
            "of 0.02119451337611614\n",
            "it 0.03381141244791276\n",
            "to 0.03666786640537887\n",
            "a 0.038663366330909006\n",
            "and 0.04855164147441471\n",
            ". 0.08574986716170675\n",
            "<unk> 0.10282928388487023\n",
            "\n",
            "state 76\n",
            "they 0.009756898630046843\n",
            "are 0.010104030647924292\n",
            "is 0.01091954737538269\n",
            "! 0.012077485090849974\n",
            "in 0.013146500490326838\n",
            "this 0.013640526408412226\n",
            "that 0.014252522099479385\n",
            "of 0.01844484634052821\n",
            "but 0.020798321778685284\n",
            "<unk> 0.02233365333983711\n",
            "for 0.02400386141464174\n",
            "a 0.0467841100747536\n",
            "the 0.053820178455633486\n",
            "and 0.06590439640531844\n",
            ". 0.06641711025375123\n",
            "\n",
            "state 77\n",
            "! 0.011029043033335758\n",
            "you 0.011402929150379909\n",
            "<unk> 0.01159913569869555\n",
            "was 0.01171544080904193\n",
            "it 0.011755671054790287\n",
            "br 0.013428586625928086\n",
            "that 0.014178402511015672\n",
            "this 0.017837080603091037\n",
            "to 0.02998835463944198\n",
            "and 0.038091334197792974\n",
            "a 0.04317020642161698\n",
            "i 0.050716503823022535\n",
            "the 0.05189709517673758\n",
            ". 0.0541824160875821\n",
            ", 0.07843814349109718\n",
            "\n",
            "state 78\n",
            "product 0.006408632790631463\n",
            "the 0.006660529312885758\n",
            "was 0.007249956556289394\n",
            "so 0.007898265345217838\n",
            "of 0.010691225026653714\n",
            "this 0.010905041059001743\n",
            "br 0.011631247101419249\n",
            "i 0.019465444699397143\n",
            "but 0.020513457012149475\n",
            "and 0.024519106210333024\n",
            "to 0.025809464017048808\n",
            "it 0.032327456208898854\n",
            ", 0.06923059030008821\n",
            ". 0.08571160423414649\n",
            "<unk> 0.13779693155491385\n",
            "\n",
            "state 79\n",
            "we 0.008304302191101233\n",
            "with 0.008929294756220908\n",
            "you 0.011279147242375484\n",
            "br 0.012150068443170063\n",
            "it 0.013290671054283396\n",
            "if 0.014156578551853479\n",
            "in 0.016715167671636093\n",
            "not 0.016907646816762833\n",
            "<unk> 0.019438346580935496\n",
            ". 0.022954855814360884\n",
            "a 0.024489099296631418\n",
            "my 0.03242379869096597\n",
            "this 0.06745728465419926\n",
            "the 0.09903560012948001\n",
            "i 0.14313632468091667\n",
            "\n",
            "state 80\n",
            ", 0.006692084199892778\n",
            "and 0.011035436554760171\n",
            "when 0.012116660083200817\n",
            "i'm 0.012142574388956348\n",
            "i've 0.012434794131749404\n",
            "we 0.018151972284044804\n",
            "if 0.019857359060599045\n",
            ". 0.02021688706085063\n",
            "it 0.020664485003995817\n",
            "my 0.02154154957067638\n",
            "<unk> 0.03226292920316604\n",
            "the 0.05671084273404361\n",
            "these 0.06369551281288127\n",
            "this 0.1179600268889767\n",
            "i 0.2772118896050112\n",
            "\n",
            "state 81\n",
            "that 0.009367764263188005\n",
            "but 0.01233437049860235\n",
            "it 0.012344350490480367\n",
            "i 0.0128049799448395\n",
            "in 0.014451081054656655\n",
            "for 0.0146960050868348\n",
            ". 0.01797141601374231\n",
            "and 0.020431276246400325\n",
            "is 0.021394414942251284\n",
            "of 0.022703750474299778\n",
            ", 0.02831531766070415\n",
            "br 0.03194395893396636\n",
            "to 0.04152702625090461\n",
            "the 0.0640626348737219\n",
            "<unk> 0.0879967272265611\n",
            "\n",
            "state 82\n",
            "was 0.008798202709173352\n",
            "to 0.010583914986263359\n",
            "have 0.010841473215338782\n",
            "are 0.01612580154487664\n",
            "in 0.016679406691109497\n",
            "for 0.017181755870223064\n",
            "<unk> 0.019721787116809924\n",
            "br 0.024502841232699055\n",
            "of 0.025601186602531762\n",
            "it 0.029018684218420243\n",
            "is 0.031453217529034745\n",
            "and 0.04747386432566005\n",
            "a 0.051665015232934104\n",
            ", 0.07506949852601953\n",
            "the 0.076166240475643\n",
            "\n",
            "state 83\n",
            "are 0.007454939658901077\n",
            "they 0.0078115911905669334\n",
            "not 0.008666708587858623\n",
            "with 0.010647448615083897\n",
            "for 0.010968632001854224\n",
            "you 0.012999971125148366\n",
            "this 0.013916664171439014\n",
            ", 0.01896677142104865\n",
            "of 0.022450110057471297\n",
            "it 0.024774966615481203\n",
            "i 0.026342387911285146\n",
            "is 0.028193641245740933\n",
            ". 0.06586190703109697\n",
            "the 0.06760380908522147\n",
            "<unk> 0.11204192028040899\n",
            "\n",
            "state 84\n",
            "that 0.00854280794240637\n",
            "but 0.00954239701665103\n",
            "have 0.010356178966710122\n",
            "the 0.010358208276019486\n",
            "for 0.010838467507547033\n",
            "my 0.011571888872596964\n",
            "to 0.01251450844022835\n",
            "of 0.013327946177598434\n",
            "a 0.016899291951798005\n",
            ", 0.021880590705518267\n",
            "and 0.023255897146153243\n",
            "i 0.024267113280214716\n",
            "is 0.02614808481114167\n",
            ". 0.06987873526247335\n",
            "<unk> 0.1530306917000965\n",
            "\n",
            "state 85\n",
            "is 0.01013616495474387\n",
            "with 0.01124500564363941\n",
            "in 0.011621472732523154\n",
            "to 0.011681744502540324\n",
            ", 0.012457310896481928\n",
            "of 0.014114218755368727\n",
            "and 0.01483245867757152\n",
            "this 0.015260690241687882\n",
            "not 0.01593524092887442\n",
            "a 0.022592641843582645\n",
            "it 0.02637504174952025\n",
            "i 0.028228731458061627\n",
            "the 0.06787335246131986\n",
            ". 0.09949909531069517\n",
            "<unk> 0.14220296253208348\n",
            "\n",
            "state 86\n",
            "that 0.009297476366165234\n",
            "not 0.009641229032069343\n",
            "are 0.010496583085908407\n",
            "of 0.011148655878554256\n",
            "and 0.011294630725701643\n",
            "it 0.012946510282747736\n",
            "is 0.014307908914643442\n",
            "but 0.014994175290445607\n",
            "to 0.01562607035685459\n",
            "this 0.015668680053610762\n",
            "a 0.024655734373570368\n",
            ", 0.025801157786392397\n",
            "the 0.028249770556388294\n",
            ". 0.10442411391547762\n",
            "<unk> 0.15835186142135557\n",
            "\n",
            "state 87\n",
            "to 0.007334591954712706\n",
            "they 0.010385784241295949\n",
            "br 0.010425994280031122\n",
            "! 0.01068397811536389\n",
            "not 0.012373894661447707\n",
            "you 0.012846493903180425\n",
            "the 0.014489748575436471\n",
            "in 0.014513102052207698\n",
            "with 0.015577730082981479\n",
            "a 0.01980514354758415\n",
            "was 0.02016849285507587\n",
            "and 0.02236929371467007\n",
            ", 0.06378296866837238\n",
            ". 0.08157025047295824\n",
            "<unk> 0.12631066327581\n",
            "\n",
            "state 88\n",
            "is 0.00945439135167866\n",
            "of 0.009784609858910224\n",
            "it 0.009928960667146403\n",
            "in 0.010159119736046475\n",
            "you 0.011060079071244535\n",
            "! 0.013086318213599417\n",
            "to 0.015595837500198948\n",
            "and 0.02332561522079738\n",
            "br 0.02433748002115399\n",
            "i 0.02708663791461504\n",
            "the 0.02793245752773979\n",
            "a 0.040944124219947926\n",
            ", 0.04339570916330411\n",
            ". 0.053044673866617764\n",
            "<unk> 0.11865769971166194\n",
            "\n",
            "state 89\n",
            "that 0.00770693190415937\n",
            "is 0.007750601294813598\n",
            "br 0.00928136768492521\n",
            "not 0.00950478476105058\n",
            "they 0.009565159584183447\n",
            "in 0.00979718132997901\n",
            "a 0.011927133369262351\n",
            "but 0.013598486472525982\n",
            "of 0.017929049472195667\n",
            "to 0.020646934096017033\n",
            "the 0.029133049500503938\n",
            ", 0.03867353780983313\n",
            ". 0.0444451933481621\n",
            "and 0.051194105761183696\n",
            "<unk> 0.15847355850265865\n",
            "\n",
            "state 90\n",
            "of 0.009628872917769116\n",
            "to 0.010198562433277228\n",
            ", 0.010579785567560401\n",
            "it's 0.01076917671423296\n",
            "for 0.010771606976349742\n",
            "great 0.011941093062511777\n",
            "in 0.01235963314907951\n",
            "and 0.014205497107311922\n",
            "a 0.020600674891978546\n",
            "these 0.021044145064843686\n",
            ". 0.037008149148308245\n",
            "<unk> 0.04208035395526054\n",
            "the 0.045207973215320114\n",
            "this 0.0758737225028094\n",
            "i 0.15561415464216674\n",
            "\n",
            "state 91\n",
            "the 0.00917900138841565\n",
            "that 0.010729697746623338\n",
            "! 0.011185269103284231\n",
            "i 0.011703197011145751\n",
            "not 0.01210083402017735\n",
            "it 0.013838065146687076\n",
            "in 0.014296499359694952\n",
            "is 0.02052456242412167\n",
            "a 0.020720852096212918\n",
            "to 0.02727154505674037\n",
            "br 0.033097073374117596\n",
            "and 0.04441919896592848\n",
            ", 0.04693633781369543\n",
            ". 0.07475203413867233\n",
            "<unk> 0.1230965286977028\n",
            "\n",
            "state 92\n",
            "my 0.00888486541109718\n",
            "but 0.008995321489444638\n",
            "is 0.00920449907418983\n",
            "you 0.010680421354313284\n",
            "in 0.013103067402541677\n",
            "it 0.016058086063128394\n",
            "not 0.016654531196515054\n",
            ", 0.02301083345704544\n",
            "and 0.023130329932914567\n",
            "br 0.03151244755357684\n",
            "to 0.03508277546019056\n",
            "<unk> 0.03796649670012307\n",
            "the 0.04621844957983802\n",
            "a 0.05180881538757383\n",
            ". 0.09275258741911938\n",
            "\n",
            "state 93\n",
            "they 0.011518383664862665\n",
            "as 0.01169024632915149\n",
            "and 0.012508307367891722\n",
            "this 0.012900386820868415\n",
            "a 0.013434304469720992\n",
            "in 0.015773706271873147\n",
            "it 0.01692849325576884\n",
            "i 0.018206536153447434\n",
            "for 0.020157695034286115\n",
            "of 0.03623322516341472\n",
            ". 0.04199136556066201\n",
            "to 0.04343703940828684\n",
            "<unk> 0.044358388867402884\n",
            "the 0.05280413417555592\n",
            ", 0.062006836274610476\n",
            "\n",
            "state 94\n",
            "so 0.010104578013453946\n",
            "to 0.010937342941309693\n",
            "not 0.011137645424177365\n",
            "that 0.011718079129110218\n",
            "the 0.012336065509688193\n",
            "but 0.01350774721117845\n",
            "br 0.015349475633801853\n",
            "in 0.016968687542526666\n",
            "of 0.020339482554039976\n",
            "is 0.021649129159759466\n",
            "and 0.03842284520381677\n",
            "a 0.044768248306735425\n",
            "<unk> 0.04492825110389678\n",
            ", 0.054036293745049944\n",
            ". 0.1441905605532269\n",
            "\n",
            "state 95\n",
            "with 0.010817592197798532\n",
            "that 0.011838816247911792\n",
            "i 0.012153524949875393\n",
            "not 0.012962053303946645\n",
            "of 0.0185225466445594\n",
            "in 0.019780002587161363\n",
            "to 0.02154388197328623\n",
            "is 0.023131844798777848\n",
            "it 0.028254553110142373\n",
            "<unk> 0.03247467767473735\n",
            "and 0.03414280722306676\n",
            "the 0.03836958943640833\n",
            "a 0.04103441892785752\n",
            ", 0.056068168706709415\n",
            ". 0.10423690888818846\n",
            "\n",
            "state 96\n",
            "not 0.009265693804496026\n",
            "that 0.009703509448111458\n",
            "have 0.009756021423624596\n",
            "but 0.010813803353289003\n",
            "in 0.011394739087709167\n",
            "as 0.011421175482787083\n",
            "are 0.013358380759205\n",
            "br 0.014083399859278724\n",
            "and 0.024291723990853453\n",
            "is 0.025351232689573747\n",
            ", 0.028593560017442895\n",
            "of 0.028675396892575256\n",
            "a 0.03259797916051235\n",
            "the 0.051099044349311604\n",
            ". 0.13026984380791054\n",
            "\n",
            "state 97\n",
            "! 0.009273167968970208\n",
            "like 0.010419041077172937\n",
            "not 0.010557677964347279\n",
            "i 0.011638219540642338\n",
            "in 0.012965425786299566\n",
            "you 0.013184805919976074\n",
            "but 0.01441941954752687\n",
            "was 0.018831265575318244\n",
            "is 0.024951669032557612\n",
            "it 0.025691292730682644\n",
            "to 0.029547666829496336\n",
            "and 0.0357716710953928\n",
            "the 0.04106945900132412\n",
            ". 0.06348833381893206\n",
            "<unk> 0.08031992759418544\n",
            "\n",
            "state 98\n",
            "my 0.008106085573454044\n",
            "was 0.009780741525314746\n",
            "are 0.009982307689243632\n",
            "have 0.010340350216761588\n",
            ". 0.010710764203511502\n",
            "! 0.011291798252852253\n",
            "is 0.015711731196844218\n",
            "of 0.015899401365701324\n",
            "you 0.01716160831221787\n",
            "and 0.021607927700231545\n",
            "to 0.03270636062551006\n",
            "i 0.0407490814884995\n",
            "the 0.047104867395377545\n",
            ", 0.05899428356011582\n",
            "<unk> 0.1273473940805014\n",
            "\n",
            "state 99\n",
            "the 0.00934010328517143\n",
            "to 0.010313572904666116\n",
            "not 0.011291072088788661\n",
            "have 0.01133368794679594\n",
            "that 0.011717570496025525\n",
            "in 0.011999565619107845\n",
            "was 0.012113179076286515\n",
            "br 0.018865930781501318\n",
            "a 0.021291284160046903\n",
            "is 0.026277409584925086\n",
            "it 0.035196119433968276\n",
            ", 0.04309981869707352\n",
            "and 0.04681090701731442\n",
            ". 0.050660116703199136\n",
            "<unk> 0.07327992172409395\n",
            "\n"
          ]
        }
      ]
    }
  ]
}